diff --git a/Cargo.lock b/Cargo.lock
index cbfd552..5120a58 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -1,17 +1,36 @@
 # This file is automatically @generated by Cargo.
 # It is not intended for manual editing.
+[[package]]
+name = "ahash"
+version = "0.2.19"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "29661b60bec623f0586702976ff4d0c9942dcb6723161c2df0eea78455cfedfb"
+dependencies = [
+ "const-random",
+]
+
+[[package]]
+name = "aho-corasick"
+version = "0.7.15"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "7404febffaa47dac81aa44dba71523c9d069b1bdc50a77db41195149e17f68e5"
+dependencies = [
+ "memchr",
+]
+
 [[package]]
 name = "algebra"
 version = "0.1.1-alpha.0"
-source = "git+https://github.com/celo-org/zexe?rev=ba217a777e8b09b59037a2a3408a0c5812ec65fb#ba217a777e8b09b59037a2a3408a0c5812ec65fb"
+source = "git+https://github.com/celo-org/zexe#5e0a369d33c3b4c45a1b3bde8d62e264fec75f08"
 dependencies = [
  "algebra-core",
+ "paste",
 ]
 
 [[package]]
 name = "algebra-core"
 version = "0.1.1-alpha.0"
-source = "git+https://github.com/celo-org/zexe?rev=ba217a777e8b09b59037a2a3408a0c5812ec65fb#ba217a777e8b09b59037a2a3408a0c5812ec65fb"
+source = "git+https://github.com/celo-org/zexe#5e0a369d33c3b4c45a1b3bde8d62e264fec75f08"
 dependencies = [
  "algebra-core-derive",
  "cc",
@@ -20,23 +39,32 @@ dependencies = [
  "itertools 0.9.0",
  "num-traits",
  "paste",
+ "peekmore",
  "rand 0.7.3",
  "rayon",
  "rustc_version",
  "unroll",
- "voracious_radix_sort",
 ]
 
 [[package]]
 name = "algebra-core-derive"
 version = "0.1.1-alpha.0"
-source = "git+https://github.com/celo-org/zexe?rev=ba217a777e8b09b59037a2a3408a0c5812ec65fb#ba217a777e8b09b59037a2a3408a0c5812ec65fb"
+source = "git+https://github.com/celo-org/zexe#5e0a369d33c3b4c45a1b3bde8d62e264fec75f08"
 dependencies = [
  "proc-macro2 1.0.24",
  "quote 1.0.7",
  "syn 1.0.45",
 ]
 
+[[package]]
+name = "ansi_term"
+version = "0.11.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "ee49baf6cb617b853aa8d93bf420db2383fab46d314482ca2803b40d5fde979b"
+dependencies = [
+ "winapi",
+]
+
 [[package]]
 name = "ansi_term"
 version = "0.12.1"
@@ -75,6 +103,12 @@ dependencies = [
  "winapi",
 ]
 
+[[package]]
+name = "autocfg"
+version = "0.1.7"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "1d49d90015b3c36167a20fe2810c5cd875ad504b39cff3d4eae7977e6b7c1cb2"
+
 [[package]]
 name = "autocfg"
 version = "1.0.1"
@@ -84,7 +118,7 @@ checksum = "cdb031dd78e28731d87d56cc8ffef4a8f36ca26c38fe2de700543e627f8a464a"
 [[package]]
 name = "bench-utils"
 version = "0.1.1-alpha.0"
-source = "git+https://github.com/celo-org/zexe?rev=ba217a777e8b09b59037a2a3408a0c5812ec65fb#ba217a777e8b09b59037a2a3408a0c5812ec65fb"
+source = "git+https://github.com/celo-org/zexe#5e0a369d33c3b4c45a1b3bde8d62e264fec75f08"
 dependencies = [
  "colored",
 ]
@@ -118,6 +152,43 @@ dependencies = [
  "constant_time_eq",
 ]
 
+[[package]]
+name = "bls-crypto"
+version = "0.2.0"
+source = "git+https://github.com/celo-org/celo-bls-snark-rs#b8dfb21efcbf8c3d09fcaeb72c211d311f73a83b"
+dependencies = [
+ "algebra",
+ "bench-utils",
+ "blake2s_simd",
+ "byteorder",
+ "clap",
+ "crypto-primitives",
+ "csv",
+ "env_logger",
+ "hex 0.3.2",
+ "log",
+ "lru",
+ "once_cell",
+ "rand 0.7.3",
+ "rand_chacha",
+ "thiserror",
+]
+
+[[package]]
+name = "bls-gadgets"
+version = "0.2.0"
+source = "git+https://github.com/celo-org/celo-bls-snark-rs#b8dfb21efcbf8c3d09fcaeb72c211d311f73a83b"
+dependencies = [
+ "algebra",
+ "algebra-core",
+ "bls-crypto",
+ "crypto-primitives",
+ "r1cs-core",
+ "r1cs-std",
+ "tracing",
+ "tracing-subscriber",
+]
+
 [[package]]
 name = "bstr"
 version = "0.2.14"
@@ -169,6 +240,12 @@ version = "0.1.10"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "4785bdd1c96b2a846b2bd7cc02e86b6b3dbf14e7e53446c4f54c92a361040822"
 
+[[package]]
+name = "cfg-if"
+version = "1.0.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "baf1de4339761588bc0619e3cbc0120ee582ebb74b53b4efbf79117bd2da40fd"
+
 [[package]]
 name = "chrono"
 version = "0.4.19"
@@ -197,9 +274,13 @@ version = "2.33.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "37e58ac78573c40708d45522f0d80fa2f01cc4f9b4e2bf749807255454312002"
 dependencies = [
+ "ansi_term 0.11.0",
+ "atty",
  "bitflags",
+ "strsim",
  "textwrap",
  "unicode-width",
+ "vec_map",
 ]
 
 [[package]]
@@ -219,10 +300,32 @@ version = "0.1.6"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "b8d976903543e0c48546a91908f21588a680a8c8f984df9a5d69feccb2b2a211"
 dependencies = [
- "cfg-if",
+ "cfg-if 0.1.10",
  "wasm-bindgen",
 ]
 
+[[package]]
+name = "const-random"
+version = "0.1.12"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "486d435a7351580347279f374cb8a3c16937485441db80181357b7c4d70f17ed"
+dependencies = [
+ "const-random-macro",
+ "proc-macro-hack",
+]
+
+[[package]]
+name = "const-random-macro"
+version = "0.1.12"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "49a84d8ff70e3ec52311109b019c27672b4c1929e4cf7c18bcf0cd9fb5e230be"
+dependencies = [
+ "getrandom 0.2.0",
+ "lazy_static",
+ "proc-macro-hack",
+ "tiny-keccak",
+]
+
 [[package]]
 name = "constant_time_eq"
 version = "0.1.5"
@@ -271,7 +374,7 @@ version = "0.7.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "69323bff1fb41c635347b8ead484a5ca6c3f11914d784170b158d8449ab07f8e"
 dependencies = [
- "cfg-if",
+ "cfg-if 0.1.10",
  "crossbeam-channel",
  "crossbeam-deque",
  "crossbeam-epoch",
@@ -306,8 +409,8 @@ version = "0.8.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "058ed274caafc1f60c4997b5fc07bf7dc7cca454af7c6e81edffe5f33f70dace"
 dependencies = [
- "autocfg",
- "cfg-if",
+ "autocfg 1.0.1",
+ "cfg-if 0.1.10",
  "crossbeam-utils",
  "lazy_static",
  "maybe-uninit",
@@ -321,7 +424,7 @@ version = "0.2.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "774ba60a54c213d409d5353bda12d49cd68d14e45036a285234c8d6f91f92570"
 dependencies = [
- "cfg-if",
+ "cfg-if 0.1.10",
  "crossbeam-utils",
  "maybe-uninit",
 ]
@@ -332,11 +435,17 @@ version = "0.7.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "c3c7c73a2d1e9fc0886a08b93e98eb643461230d5f1925e4036204d5f2e261a8"
 dependencies = [
- "autocfg",
- "cfg-if",
+ "autocfg 1.0.1",
+ "cfg-if 0.1.10",
  "lazy_static",
 ]
 
+[[package]]
+name = "crunchy"
+version = "0.2.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "7a81dae078cea95a014a339291cec439d2f232ebe854a9d672b796c6afafa9b7"
+
 [[package]]
 name = "crypto-mac"
 version = "0.7.0"
@@ -347,6 +456,26 @@ dependencies = [
  "subtle",
 ]
 
+[[package]]
+name = "crypto-primitives"
+version = "0.1.1-alpha.0"
+source = "git+https://github.com/celo-org/zexe#5e0a369d33c3b4c45a1b3bde8d62e264fec75f08"
+dependencies = [
+ "algebra-core",
+ "bench-utils",
+ "blake2",
+ "derivative",
+ "digest",
+ "ff-fft",
+ "gm17",
+ "groth16",
+ "r1cs-core",
+ "r1cs-std",
+ "rand 0.7.3",
+ "rayon",
+ "tracing",
+]
+
 [[package]]
 name = "csv"
 version = "1.1.3"
@@ -395,6 +524,19 @@ version = "1.6.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "e78d4f1cc4ae33bbfc157ed5d5a5ef3bc29227303d595861deb238fcec4e9457"
 
+[[package]]
+name = "env_logger"
+version = "0.6.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "aafcde04e90a5226a6443b7aabdb016ba2f8307c847d524724bd9b346dd1a2d3"
+dependencies = [
+ "atty",
+ "humantime",
+ "log",
+ "regex",
+ "termcolor",
+]
+
 [[package]]
 name = "envmnt"
 version = "0.8.4"
@@ -405,10 +547,31 @@ dependencies = [
  "indexmap",
 ]
 
+[[package]]
+name = "epoch-snark"
+version = "0.2.0"
+source = "git+https://github.com/celo-org/celo-bls-snark-rs#b8dfb21efcbf8c3d09fcaeb72c211d311f73a83b"
+dependencies = [
+ "algebra",
+ "algebra-core",
+ "blake2s_simd",
+ "bls-crypto",
+ "bls-gadgets",
+ "byteorder",
+ "crypto-primitives",
+ "groth16",
+ "r1cs-core",
+ "r1cs-std",
+ "rand 0.7.3",
+ "thiserror",
+ "tracing",
+ "tracing-subscriber",
+]
+
 [[package]]
 name = "ff-fft"
 version = "0.1.1-alpha.0"
-source = "git+https://github.com/celo-org/zexe?rev=ba217a777e8b09b59037a2a3408a0c5812ec65fb#ba217a777e8b09b59037a2a3408a0c5812ec65fb"
+source = "git+https://github.com/celo-org/zexe#5e0a369d33c3b4c45a1b3bde8d62e264fec75f08"
 dependencies = [
  "algebra-core",
  "rand 0.7.3",
@@ -457,16 +620,40 @@ version = "0.1.15"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "fc587bc0ec293155d5bfa6b9891ec18a1e330c234f896ea47fbada4cadbe47e6"
 dependencies = [
- "cfg-if",
+ "cfg-if 0.1.10",
  "libc",
  "wasi 0.9.0+wasi-snapshot-preview1",
  "wasm-bindgen",
 ]
 
+[[package]]
+name = "getrandom"
+version = "0.2.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "ee8025cf36f917e6a52cce185b7c7177689b838b7ec138364e50cc2277a56cf4"
+dependencies = [
+ "cfg-if 0.1.10",
+ "libc",
+ "wasi 0.9.0+wasi-snapshot-preview1",
+]
+
+[[package]]
+name = "gm17"
+version = "0.1.1-alpha.0"
+source = "git+https://github.com/celo-org/zexe#5e0a369d33c3b4c45a1b3bde8d62e264fec75f08"
+dependencies = [
+ "algebra-core",
+ "bench-utils",
+ "ff-fft",
+ "r1cs-core",
+ "rand 0.7.3",
+ "rayon",
+]
+
 [[package]]
 name = "groth16"
 version = "0.1.1-alpha.0"
-source = "git+https://github.com/celo-org/zexe?rev=ba217a777e8b09b59037a2a3408a0c5812ec65fb#ba217a777e8b09b59037a2a3408a0c5812ec65fb"
+source = "git+https://github.com/celo-org/zexe#5e0a369d33c3b4c45a1b3bde8d62e264fec75f08"
 dependencies = [
  "algebra-core",
  "bench-utils",
@@ -502,6 +689,16 @@ version = "1.6.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "d36fab90f82edc3c747f9d438e06cf0a491055896f2a279638bb5beed6c40177"
 
+[[package]]
+name = "hashbrown"
+version = "0.6.3"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "8e6073d0ca812575946eb5f35ff68dbe519907b25c42530389ff946dc84c6ead"
+dependencies = [
+ "ahash",
+ "autocfg 0.1.7",
+]
+
 [[package]]
 name = "hashbrown"
 version = "0.9.1"
@@ -517,20 +714,35 @@ dependencies = [
  "libc",
 ]
 
+[[package]]
+name = "hex"
+version = "0.3.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "805026a5d0141ffc30abb3be3173848ad46a1b1664fe632428479619a3644d77"
+
 [[package]]
 name = "hex"
 version = "0.4.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "644f9158b2f133fd50f5fb3242878846d9eb792e445c893805ff0e3824006e35"
 
+[[package]]
+name = "humantime"
+version = "1.3.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "df004cfca50ef23c36850aaaa59ad52cc70d0e90243c3c7737a4dd32dc7a3c4f"
+dependencies = [
+ "quick-error",
+]
+
 [[package]]
 name = "indexmap"
 version = "1.6.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "55e2e4c765aa53a0424761bf9f41aa7a6ac1efa87238f59560640e27fca028f2"
 dependencies = [
- "autocfg",
- "hashbrown",
+ "autocfg 1.0.1",
+ "hashbrown 0.9.1",
 ]
 
 [[package]]
@@ -584,7 +796,16 @@ version = "0.4.11"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "4fabed175da42fed1fa0746b0ea71f412aa9d35e76e95e59b192c64b9dc2bf8b"
 dependencies = [
- "cfg-if",
+ "cfg-if 0.1.10",
+]
+
+[[package]]
+name = "lru"
+version = "0.4.3"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "0609345ddee5badacf857d4f547e0e5a2e987db77085c24cd887f73573a04237"
+dependencies = [
+ "hashbrown 0.6.3",
 ]
 
 [[package]]
@@ -641,7 +862,7 @@ version = "0.5.6"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "043175f069eda7b85febe4a74abbaeff828d9f8b448515d3151a14a3542811aa"
 dependencies = [
- "autocfg",
+ "autocfg 1.0.1",
 ]
 
 [[package]]
@@ -656,7 +877,7 @@ version = "0.1.43"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "8d59457e662d541ba17869cf51cf177c0b5f0cbf476c66bdc90bf1edac4f875b"
 dependencies = [
- "autocfg",
+ "autocfg 1.0.1",
  "num-traits",
 ]
 
@@ -666,7 +887,7 @@ version = "0.2.12"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "ac267bcc07f48ee5f8935ab0d24f316fb722d7a1292e2913f0cc196b29ffd611"
 dependencies = [
- "autocfg",
+ "autocfg 1.0.1",
 ]
 
 [[package]]
@@ -679,6 +900,12 @@ dependencies = [
  "libc",
 ]
 
+[[package]]
+name = "once_cell"
+version = "1.5.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "13bd41f508810a131401606d54ac32a467c97172d74ba7662562ebba5ad07fa0"
+
 [[package]]
 name = "oorandom"
 version = "11.1.2"
@@ -710,6 +937,15 @@ dependencies = [
  "proc-macro-hack",
 ]
 
+[[package]]
+name = "peekmore"
+version = "0.5.6"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "4089f831c514cbf080bd19bfce702f7a2de250492730d419204af6710ba19316"
+dependencies = [
+ "smallvec",
+]
+
 [[package]]
 name = "phase1"
 version = "0.3.0"
@@ -719,7 +955,7 @@ dependencies = [
  "anyhow",
  "bench-utils",
  "blake2",
- "cfg-if",
+ "cfg-if 0.1.10",
  "criterion",
  "derivative",
  "ff-fft",
@@ -743,7 +979,7 @@ version = "0.3.0"
 dependencies = [
  "algebra",
  "gumdrop",
- "hex",
+ "hex 0.4.2",
  "memmap",
  "phase1",
  "rand 0.7.3",
@@ -780,7 +1016,7 @@ version = "0.3.0"
 dependencies = [
  "algebra",
  "byteorder",
- "cfg-if",
+ "cfg-if 0.1.10",
  "console_error_panic_hook",
  "crossbeam",
  "groth16",
@@ -801,6 +1037,29 @@ dependencies = [
  "web-sys",
 ]
 
+[[package]]
+name = "phase2-cli"
+version = "0.3.0"
+dependencies = [
+ "algebra",
+ "bench-utils",
+ "epoch-snark",
+ "groth16",
+ "gumdrop",
+ "hex 0.4.2",
+ "memmap",
+ "phase1",
+ "phase2",
+ "r1cs-core",
+ "rand 0.7.3",
+ "rand_xorshift",
+ "rustc_version",
+ "setup-utils",
+ "tracing",
+ "tracing-subscriber",
+ "wasm-bindgen-test",
+]
+
 [[package]]
 name = "pin-project-lite"
 version = "0.1.10"
@@ -863,6 +1122,12 @@ dependencies = [
  "unicode-xid 0.2.1",
 ]
 
+[[package]]
+name = "quick-error"
+version = "1.2.3"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "a1d01941d82fa2ab50be1e79e6714289dd7cde78eba4c074bc5a4374f650dfe0"
+
 [[package]]
 name = "quote"
 version = "0.6.13"
@@ -884,7 +1149,7 @@ dependencies = [
 [[package]]
 name = "r1cs-core"
 version = "0.1.1-alpha.0"
-source = "git+https://github.com/celo-org/zexe?rev=ba217a777e8b09b59037a2a3408a0c5812ec65fb#ba217a777e8b09b59037a2a3408a0c5812ec65fb"
+source = "git+https://github.com/celo-org/zexe#5e0a369d33c3b4c45a1b3bde8d62e264fec75f08"
 dependencies = [
  "algebra-core",
  "tracing",
@@ -894,7 +1159,7 @@ dependencies = [
 [[package]]
 name = "r1cs-std"
 version = "0.1.1-alpha.0"
-source = "git+https://github.com/scipr-lab/zexe#85cac1770dddd4da79e9993c5d1dcb5732db08f5"
+source = "git+https://github.com/celo-org/zexe#5e0a369d33c3b4c45a1b3bde8d62e264fec75f08"
 dependencies = [
  "algebra",
  "derivative",
@@ -931,7 +1196,7 @@ version = "0.7.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "6a6b1679d49b24bbfe0c803429aa1874472f50d9b363131f0e89fc356b544d03"
 dependencies = [
- "getrandom",
+ "getrandom 0.1.15",
  "libc",
  "rand_chacha",
  "rand_core 0.5.1",
@@ -969,7 +1234,7 @@ version = "0.5.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "90bde5296fc891b0cef12a6d03ddccc162ce7b2aff54160af9338f8d40df6d19"
 dependencies = [
- "getrandom",
+ "getrandom 0.1.15",
 ]
 
 [[package]]
@@ -996,7 +1261,7 @@ version = "1.4.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "dcf6960dc9a5b4ee8d3e4c5787b4a112a8818e0290a42ff664ad60692fdf2032"
 dependencies = [
- "autocfg",
+ "autocfg 1.0.1",
  "crossbeam-deque",
  "either",
  "rayon-core",
@@ -1030,7 +1295,10 @@ version = "1.4.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "8963b85b8ce3074fecffde43b4b0dded83ce2f367dc8d363afc56679f3ee820b"
 dependencies = [
+ "aho-corasick",
+ "memchr",
  "regex-syntax",
+ "thread_local",
 ]
 
 [[package]]
@@ -1176,10 +1444,11 @@ dependencies = [
  "algebra",
  "blake2",
  "blake2s_simd",
- "cfg-if",
+ "cfg-if 0.1.10",
  "criterion",
  "crossbeam",
  "ff-fft",
+ "groth16",
  "num_cpus",
  "phase1",
  "r1cs-core",
@@ -1208,6 +1477,12 @@ version = "1.4.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "fbee7696b84bbf3d89a1c2eccff0850e3047ed46bfcd2e92c29a2d074d57e252"
 
+[[package]]
+name = "strsim"
+version = "0.8.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "8ea5119cdb4c55b55d432abb513a0429384878c15dde60cc77b1c99de1a95a6a"
+
 [[package]]
 name = "subtle"
 version = "1.0.0"
@@ -1236,6 +1511,15 @@ dependencies = [
  "unicode-xid 0.2.1",
 ]
 
+[[package]]
+name = "termcolor"
+version = "1.1.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "2dfed899f0eb03f32ee8c6a0aabdb8a7949659e3466561fc0adf54e26d88c5f4"
+dependencies = [
+ "winapi-util",
+]
+
 [[package]]
 name = "textwrap"
 version = "0.11.0"
@@ -1285,6 +1569,15 @@ dependencies = [
  "winapi",
 ]
 
+[[package]]
+name = "tiny-keccak"
+version = "2.0.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "2c9d3793400a45f954c52e73d068316d76b6f4e36977e3fcebb13a2721e80237"
+dependencies = [
+ "crunchy",
+]
+
 [[package]]
 name = "tinytemplate"
 version = "1.1.0"
@@ -1310,7 +1603,7 @@ version = "0.1.21"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "b0987850db3733619253fe60e17cb59b82d37c7e6c0236bb81e4d6b87c879f27"
 dependencies = [
- "cfg-if",
+ "cfg-if 0.1.10",
  "pin-project-lite",
  "tracing-attributes",
  "tracing-core",
@@ -1363,7 +1656,7 @@ version = "0.2.13"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "4ef0a5e15477aa303afbfac3a44cba9b6430fdaad52423b1e6c0dbbe28c3eedd"
 dependencies = [
- "ansi_term",
+ "ansi_term 0.12.1",
  "chrono",
  "lazy_static",
  "matchers",
@@ -1414,10 +1707,10 @@ dependencies = [
 ]
 
 [[package]]
-name = "voracious_radix_sort"
-version = "0.1.0"
+name = "vec_map"
+version = "0.8.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "616c76cba4a47731b29152961b4b6861156b03cdb339683a9cef81d0cc5e53cf"
+checksum = "f1bddf1187be692e79c5ffeab891132dfb0f236ed36a43c7ed39f1165ee20191"
 
 [[package]]
 name = "walkdir"
@@ -1444,11 +1737,11 @@ checksum = "1a143597ca7c7793eff794def352d41792a93c481eb1042423ff7ff72ba2c31f"
 
 [[package]]
 name = "wasm-bindgen"
-version = "0.2.68"
+version = "0.2.69"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1ac64ead5ea5f05873d7c12b545865ca2b8d28adfc50a49b84770a3a97265d42"
+checksum = "3cd364751395ca0f68cafb17666eee36b63077fb5ecd972bbcd74c90c4bf736e"
 dependencies = [
- "cfg-if",
+ "cfg-if 1.0.0",
  "serde",
  "serde_json",
  "wasm-bindgen-macro",
@@ -1456,9 +1749,9 @@ dependencies = [
 
 [[package]]
 name = "wasm-bindgen-backend"
-version = "0.2.68"
+version = "0.2.69"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "f22b422e2a757c35a73774860af8e112bff612ce6cb604224e8e47641a9e4f68"
+checksum = "1114f89ab1f4106e5b55e688b828c0ab0ea593a1ea7c094b141b14cbaaec2d62"
 dependencies = [
  "bumpalo",
  "lazy_static",
@@ -1475,7 +1768,7 @@ version = "0.4.18"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "b7866cab0aa01de1edf8b5d7936938a7e397ee50ce24119aef3e1eaa3b6171da"
 dependencies = [
- "cfg-if",
+ "cfg-if 0.1.10",
  "js-sys",
  "wasm-bindgen",
  "web-sys",
@@ -1483,9 +1776,9 @@ dependencies = [
 
 [[package]]
 name = "wasm-bindgen-macro"
-version = "0.2.68"
+version = "0.2.69"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "6b13312a745c08c469f0b292dd2fcd6411dba5f7160f593da6ef69b64e407038"
+checksum = "7a6ac8995ead1f084a8dea1e65f194d0973800c7f571f6edd70adf06ecf77084"
 dependencies = [
  "quote 1.0.7",
  "wasm-bindgen-macro-support",
@@ -1493,9 +1786,9 @@ dependencies = [
 
 [[package]]
 name = "wasm-bindgen-macro-support"
-version = "0.2.68"
+version = "0.2.69"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "f249f06ef7ee334cc3b8ff031bfc11ec99d00f34d86da7498396dc1e3b1498fe"
+checksum = "b5a48c72f299d80557c7c62e37e7225369ecc0c963964059509fbafe917c7549"
 dependencies = [
  "proc-macro2 1.0.24",
  "quote 1.0.7",
@@ -1506,9 +1799,9 @@ dependencies = [
 
 [[package]]
 name = "wasm-bindgen-shared"
-version = "0.2.68"
+version = "0.2.69"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1d649a3145108d7d3fbcde896a468d1bd636791823c9921135218ad89be08307"
+checksum = "7e7811dd7f9398f14cc76efd356f98f03aa30419dea46aa810d71e819fc97158"
 
 [[package]]
 name = "wasm-bindgen-test"
diff --git a/Cargo.toml b/Cargo.toml
index 30fbdc7..24efef5 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -4,13 +4,15 @@ members = [
     "./phase1-cli",
     "./phase1-wasm",
     "./phase2",
+    "./phase2-cli",
     "./setup-utils",
 ]
 
 [patch.'https://github.com/scipr-lab/zexe']
-zexe_algebra_core = { git = "https://github.com/celo-org/zexe", rev = "ba217a777e8b09b59037a2a3408a0c5812ec65fb", package = "algebra-core", default-features = false, features = ["derive"] }
-zexe_algebra = { git = "https://github.com/celo-org/zexe", rev = "ba217a777e8b09b59037a2a3408a0c5812ec65fb", package = "algebra", default-features = false, features = ["ed_on_bls12_381", "bls12_381", "bls12_377"] }
-zexe_fft = { git = "https://github.com/celo-org/zexe", rev = "ba217a777e8b09b59037a2a3408a0c5812ec65fb", package = "ff-fft", default-features = false, features = ["ed_on_bls12_381", "bls12_381", "bls12_377"] }
-zexe_bench_utils = { git = "https://github.com/celo-org/zexe", rev = "ba217a777e8b09b59037a2a3408a0c5812ec65fb", package = "bench-utils", default-features = false, features = ["ed_on_bls12_381", "bls12_381", "bls12_377"] }
-zexe_r1cs_core = { git = "https://github.com/celo-org/zexe", rev = "ba217a777e8b09b59037a2a3408a0c5812ec65fb", package = "r1cs-core", default-features = false, features = ["ed_on_bls12_381", "bls12_381", "bls12_377"] }
-zexe_groth16 = { git = "https://github.com/celo-org/zexe", rev = "ba217a777e8b09b59037a2a3408a0c5812ec65fb", package = "groth16", default-features = false, features = [] }
+algebra_core = { git = "https://github.com/celo-org/zexe", package = "algebra-core", default-features = false, features = ["derive"] }
+algebra = { git = "https://github.com/celo-org/zexe", package = "algebra", default-features = false, features = ["ed_on_bls12_381", "bls12_381", "bls12_377"] }
+fft = { git = "https://github.com/celo-org/zexe", package = "ff-fft", default-features = false, features = ["ed_on_bls12_381", "bls12_381", "bls12_377"] }
+bench_utils = { git = "https://github.com/celo-org/zexe", package = "bench-utils", default-features = false, features = ["ed_on_bls12_381", "bls12_381", "bls12_377"] }
+r1cs_core = { git = "https://github.com/celo-org/zexe", package = "r1cs-core", default-features = false }
+r1cs_std = { git = "https://github.com/celo-org/zexe", package = "r1cs-std", default-features = false, features = ["ed_on_bls12_381", "bls12_381", "bls12_377"] }
+groth16 = { git = "https://github.com/celo-org/zexe", package = "groth16", default-features = false, features = [] }
\ No newline at end of file
diff --git a/phase1-cli/Cargo.toml b/phase1-cli/Cargo.toml
index 8b556bc..226e5c2 100644
--- a/phase1-cli/Cargo.toml
+++ b/phase1-cli/Cargo.toml
@@ -12,7 +12,7 @@ edition = "2018"
 phase1 = { path = "../phase1", default-features = false }
 setup-utils = { path = "../setup-utils", default-features = false }
 
-zexe_algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra", features = ["bls12_377", "bw6_761", "derive"] }
+algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra", features = ["bls12_377", "bw6_761", "derive"] }
 
 gumdrop = { version = "0.7.0" }
 hex = { version = "0.4.2" }
@@ -31,8 +31,8 @@ rustc_version = { version = "0.2" }
 [features]
 default = ["cli", "bw6_asm" ]
 cli = ["phase1/cli", "parallel", "setup-utils/cli"]
-parallel = ["phase1/parallel", "setup-utils/parallel", "zexe_algebra/parallel"]
-bw6_asm = [ "zexe_algebra/bw6_asm" ]
+parallel = ["phase1/parallel", "setup-utils/parallel", "algebra/parallel"]
+bw6_asm = [ "algebra/bw6_asm" ]
 
 [[bin]]
 name = "phase1"
diff --git a/phase1-cli/scripts/phase1_chunked_prepare_phase2.sh b/phase1-cli/scripts/phase1_chunked_prepare_phase2.sh
new file mode 100755
index 0000000..ca06409
--- /dev/null
+++ b/phase1-cli/scripts/phase1_chunked_prepare_phase2.sh
@@ -0,0 +1,76 @@
+#!/bin/bash -e
+
+rm -f challenge* response* new_challenge* new_response* new_new_challenge_* processed* initial_ceremony* response_list* combined* seed* chunk* phase1
+
+export RUSTFLAGS="-C target-feature=+bmi2,+adx"
+CARGO_VER=""
+PROVING_SYSTEM=$1
+POWER=18
+BATCH=131072
+CHUNK_SIZE=131072
+if [ "$PROVING_SYSTEM" == "groth16" ]; then
+  MAX_CHUNK_INDEX=$((4-1)) # we have 4 chunks, since we have a total of 2^11-1 powers
+else
+  MAX_CHUNK_INDEX=$((2-1)) # we have 2 chunks, since we have a total of 2^11-1 powers
+fi
+CURVE="bw6"
+SEED1=$(tr -dc 'A-F0-9' < /dev/urandom | head -c32)
+echo $SEED1 > seed1
+SEED2=$(tr -dc 'A-F0-9' < /dev/urandom | head -c32)
+echo $SEED2 > seed2
+
+function check_hash() {
+  test "`xxd -p -c 64 $1.hash`" = "`b2sum $1 | awk '{print $1}'`"
+}
+
+cargo $CARGO_VER build --release --bin phase1
+cargo $CARGO_VER build --release --bin prepare_phase2
+
+phase1_1="../../target/release/phase1 --curve-kind $CURVE --batch-size $BATCH --contribution-mode chunked --chunk-size $CHUNK_SIZE --power $POWER --seed seed1 --proving-system $PROVING_SYSTEM"
+phase1_2="../../target/release/phase1 --curve-kind $CURVE --batch-size $BATCH --contribution-mode chunked --chunk-size $CHUNK_SIZE --power $POWER --seed seed2 --proving-system $PROVING_SYSTEM"
+phase1_combine="../../target/release/phase1 --curve-kind $CURVE --batch-size $BATCH --contribution-mode chunked --chunk-size $CHUNK_SIZE --power $POWER --proving-system $PROVING_SYSTEM"
+phase1_full="../../target/release/phase1 --curve-kind $CURVE --batch-size $BATCH --contribution-mode full --power $POWER --proving-system $PROVING_SYSTEM"
+prepare_phase2="../../target/release/prepare_phase2 --curve-kind $CURVE --batch-size $BATCH --power $POWER --proving-system $PROVING_SYSTEM"
+####### Phase 1
+
+for i in $(seq 0 $(($MAX_CHUNK_INDEX/2))); do
+  echo "Contributing and verifying chunk $i..."
+  $phase1_1 --chunk-index $i new --challenge-fname challenge_$i --challenge-hash-fname challenge_$i.verified.hash
+  yes | $phase1_1 --chunk-index $i contribute --challenge-fname challenge_$i --challenge-hash-fname challenge_$i.hash --response-fname response_$i --response-hash-fname response_$i.hash
+  check_hash challenge_$i
+  check_hash response_$i
+  $phase1_1 --chunk-index $i verify-and-transform-pok-and-correctness --challenge-fname challenge_$i --challenge-hash-fname challenge_$i.verified.hash --response-fname response_$i --response-hash-fname response_$i.verified.hash --new-challenge-fname new_challenge_$i --new-challenge-hash-fname new_challenge_$i.verified.hash
+  yes | $phase1_2 --chunk-index $i contribute --challenge-fname new_challenge_$i --challenge-hash-fname new_challenge_$i.hash --response-fname new_response_$i --response-hash-fname new_response_$i.hash
+  check_hash new_challenge_$i
+  check_hash new_response_$i
+  $phase1_2 --chunk-index $i verify-and-transform-pok-and-correctness --challenge-fname new_challenge_$i  --challenge-hash-fname new_challenge_$i.verified.hash --response-fname new_response_$i --new-challenge-fname new_new_challenge_$i --response-hash-fname new_response_$i.verified.hash --new-challenge-hash-fname new_new_challenge_$i.verified.hash
+  rm challenge_$i new_challenge_$i new_new_challenge_$i # no longer needed
+  echo new_response_$i >> response_list
+done
+
+for i in $(seq $(($MAX_CHUNK_INDEX/2 + 1)) $MAX_CHUNK_INDEX); do
+  echo "Contributing and verifying chunk $i..."
+  $phase1_1 --chunk-index $i new --challenge-fname challenge_$i --challenge-hash-fname challenge_$i.verified.hash
+  yes | $phase1_2 --chunk-index $i contribute --challenge-fname challenge_$i --challenge-hash-fname challenge_$i.hash --response-fname response_$i --response-hash-fname response_$i.hash
+  check_hash challenge_$i
+  check_hash response_$i
+  $phase1_1 --chunk-index $i verify-and-transform-pok-and-correctness --challenge-fname challenge_$i --challenge-hash-fname challenge_$i.verified.hash --response-fname response_$i --response-hash-fname response_$i.verified.hash --new-challenge-fname new_challenge_$i --new-challenge-hash-fname new_challenge_$i.verified.hash
+  yes | $phase1_1 --chunk-index $i contribute --challenge-fname new_challenge_$i --challenge-hash-fname new_challenge_$i.hash --response-fname new_response_$i --response-hash-fname new_response_$i.hash
+  check_hash new_challenge_$i
+  check_hash new_response_$i
+  $phase1_2 --chunk-index $i verify-and-transform-pok-and-correctness --challenge-fname new_challenge_$i  --challenge-hash-fname new_challenge_$i.verified.hash --response-fname new_response_$i --new-challenge-fname new_new_challenge_$i --response-hash-fname new_response_$i.verified.hash --new-challenge-hash-fname new_new_challenge_$i.verified.hash
+  rm challenge_$i new_challenge_$i new_new_challenge_$i # no longer needed
+  echo new_response_$i >> response_list
+done
+
+echo "Aggregating..."
+$phase1_combine combine --response-list-fname response_list --combined-fname combined
+echo "Apply beacon..."
+$phase1_full beacon --challenge-fname combined --response-fname response_beacon --beacon-hash 0000000000000000000a558a61ddc8ee4e488d647a747fe4dcc362fe2026c620
+echo "Verifying..."
+$phase1_full verify-and-transform-pok-and-correctness --challenge-fname combined --challenge-hash-fname combined.verified.hash --response-fname response_beacon --response-hash-fname response_beacon.verified.hash --new-challenge-fname response_beacon_new_challenge --new-challenge-hash-fname response_beacon_new_challenge.verified.hash
+$phase1_full verify-and-transform-ratios --response-fname response_beacon_new_challenge
+echo "Running prepare phase2..."
+$prepare_phase2 --phase2-fname phase1 --response-fname response_beacon
+
+echo "Done!"
\ No newline at end of file
diff --git a/phase1-cli/src/bin/phase1.rs b/phase1-cli/src/bin/phase1.rs
index 73cbb30..bccc78b 100644
--- a/phase1-cli/src/bin/phase1.rs
+++ b/phase1-cli/src/bin/phase1.rs
@@ -1,13 +1,14 @@
-use phase1::{helpers::CurveKind, CurveParameters, Phase1Parameters};
+use phase1::{CurveParameters, Phase1Parameters};
 use phase1_cli::{
     combine, contribute, new_challenge, split, transform_pok_and_correctness, transform_ratios, Command, Phase1Opts,
 };
 use setup_utils::{
-    derive_rng_from_seed, from_slice, upgrade_correctness_check_config, DEFAULT_CONTRIBUTE_CHECK_INPUT_CORRECTNESS,
-    DEFAULT_VERIFY_CHECK_INPUT_CORRECTNESS, DEFAULT_VERIFY_CHECK_OUTPUT_CORRECTNESS,
+    converters::CurveKind, derive_rng_from_seed, from_slice, upgrade_correctness_check_config,
+    DEFAULT_CONTRIBUTE_CHECK_INPUT_CORRECTNESS, DEFAULT_VERIFY_CHECK_INPUT_CORRECTNESS,
+    DEFAULT_VERIFY_CHECK_OUTPUT_CORRECTNESS,
 };
 
-use zexe_algebra::{Bls12_377, PairingEngine as Engine, BW6_761};
+use algebra::{Bls12_377, PairingEngine as Engine, BW6_761};
 
 use gumdrop::Options;
 use std::{fs::read_to_string, process, time::Instant};
diff --git a/phase1-cli/src/bin/prepare_phase2.rs b/phase1-cli/src/bin/prepare_phase2.rs
index 1a6cf6c..58bba8f 100644
--- a/phase1-cli/src/bin/prepare_phase2.rs
+++ b/phase1-cli/src/bin/prepare_phase2.rs
@@ -1,11 +1,8 @@
-use phase1::{
-    helpers::{curve_from_str, proving_system_from_str, CurveKind},
-    parameters::*,
-    Phase1,
-};
+use phase1::{parameters::*, Phase1};
+use setup_utils::converters::{curve_from_str, proving_system_from_str, CurveKind, ProvingSystem};
 use setup_utils::{CheckForCorrectness, Groth16Params, Result, UseCompression};
 
-use zexe_algebra::{Bls12_377, PairingEngine, BW6_761};
+use algebra::{Bls12_377, PairingEngine, BW6_761};
 
 use gumdrop::Options;
 use memmap::*;
@@ -37,13 +34,8 @@ struct PreparePhase2Opts {
     pub proving_system: ProvingSystem,
     #[options(help = "the size of batches to process", default = "256")]
     pub batch_size: usize,
-    #[options(
-        help = "the number of powers used for phase 1 (circuit size will be 2^{power})",
-        default = "21"
-    )]
+    #[options(help = "the number of powers used for phase 1 (circuit size will be 2^{power})")]
     pub power: usize,
-    #[options(help = "the size (in powers) of the phase 2 circuit", default = "21")]
-    pub phase2_size: u32,
 }
 
 fn prepare_phase2<E: PairingEngine + Sync>(opts: &PreparePhase2Opts) -> Result<()> {
@@ -78,7 +70,7 @@ fn prepare_phase2<E: PairingEngine + Sync>(opts: &PreparePhase2Opts) -> Result<(
 
     // Load the elements to the Groth16 utility
     let groth16_params = Groth16Params::<E>::new(
-        2usize.pow(opts.phase2_size),
+        1 << opts.power,
         current_accumulator.tau_powers_g1,
         current_accumulator.tau_powers_g2,
         current_accumulator.alpha_tau_powers_g1,
diff --git a/phase1-cli/src/combine.rs b/phase1-cli/src/combine.rs
index d5eed60..7f65f63 100644
--- a/phase1-cli/src/combine.rs
+++ b/phase1-cli/src/combine.rs
@@ -1,7 +1,7 @@
 use phase1::{Phase1, Phase1Parameters};
 use setup_utils::UseCompression;
 
-use zexe_algebra::PairingEngine as Engine;
+use algebra::PairingEngine as Engine;
 
 use memmap::*;
 use std::{
diff --git a/phase1-cli/src/contribute.rs b/phase1-cli/src/contribute.rs
index f18fda2..aa31bd8 100644
--- a/phase1-cli/src/contribute.rs
+++ b/phase1-cli/src/contribute.rs
@@ -1,7 +1,7 @@
 use phase1::{Phase1, Phase1Parameters};
 use setup_utils::{calculate_hash, print_hash, BatchExpMode, CheckForCorrectness, UseCompression};
 
-use zexe_algebra::PairingEngine as Engine;
+use algebra::PairingEngine as Engine;
 
 use memmap::*;
 use rand::Rng;
diff --git a/phase1-cli/src/lib.rs b/phase1-cli/src/lib.rs
index 96f18e7..705adc6 100644
--- a/phase1-cli/src/lib.rs
+++ b/phase1-cli/src/lib.rs
@@ -20,16 +20,16 @@ pub use transform_pok_and_correctness::transform_pok_and_correctness;
 mod transform_ratios;
 pub use transform_ratios::transform_ratios;
 
-use phase1::{
-    helpers::{
+use setup_utils::converters::{ContributionMode, CurveKind, ProvingSystem};
+
+use gumdrop::Options;
+use setup_utils::{
+    converters::{
         batch_exp_mode_from_str, contribution_mode_from_str, curve_from_str, proving_system_from_str,
-        subgroup_check_mode_from_str, CurveKind,
+        subgroup_check_mode_from_str,
     },
-    ContributionMode, ProvingSystem,
+    BatchExpMode, SubgroupCheckMode,
 };
-
-use gumdrop::Options;
-use setup_utils::{BatchExpMode, SubgroupCheckMode};
 use std::default::Default;
 
 #[derive(Debug, Options, Clone)]
diff --git a/phase1-cli/src/new_challenge.rs b/phase1-cli/src/new_challenge.rs
index 551629e..c23aa50 100644
--- a/phase1-cli/src/new_challenge.rs
+++ b/phase1-cli/src/new_challenge.rs
@@ -1,7 +1,7 @@
 use phase1::{Phase1, Phase1Parameters};
 use setup_utils::{blank_hash, calculate_hash, print_hash, UseCompression};
 
-use zexe_algebra::PairingEngine as Engine;
+use algebra::PairingEngine as Engine;
 
 use memmap::*;
 use std::{fs::OpenOptions, io::Write};
diff --git a/phase1-cli/src/split.rs b/phase1-cli/src/split.rs
index ea4840e..2ba0799 100644
--- a/phase1-cli/src/split.rs
+++ b/phase1-cli/src/split.rs
@@ -1,7 +1,7 @@
 use phase1::{Phase1, Phase1Parameters, ProvingSystem};
 use setup_utils::UseCompression;
 
-use zexe_algebra::PairingEngine as Engine;
+use algebra::PairingEngine as Engine;
 
 use memmap::*;
 use std::fs::OpenOptions;
diff --git a/phase1-cli/src/transform_pok_and_correctness.rs b/phase1-cli/src/transform_pok_and_correctness.rs
index 2f6ff58..561d842 100644
--- a/phase1-cli/src/transform_pok_and_correctness.rs
+++ b/phase1-cli/src/transform_pok_and_correctness.rs
@@ -1,6 +1,6 @@
+use algebra::PairingEngine as Engine;
 use phase1::{Phase1, Phase1Parameters, PublicKey};
 use setup_utils::{calculate_hash, print_hash, CheckForCorrectness, SubgroupCheckMode, UseCompression};
-use zexe_algebra::PairingEngine as Engine;
 
 use memmap::*;
 use std::{
diff --git a/phase1-cli/src/transform_ratios.rs b/phase1-cli/src/transform_ratios.rs
index fb05993..2e01de4 100644
--- a/phase1-cli/src/transform_ratios.rs
+++ b/phase1-cli/src/transform_ratios.rs
@@ -1,7 +1,7 @@
 use phase1::{Phase1, Phase1Parameters};
 use setup_utils::{calculate_hash, print_hash, CheckForCorrectness, UseCompression};
 
-use zexe_algebra::PairingEngine as Engine;
+use algebra::PairingEngine as Engine;
 
 use memmap::*;
 use std::fs::OpenOptions;
diff --git a/phase1-wasm/Cargo.toml b/phase1-wasm/Cargo.toml
index e7b1ea9..2d8ce48 100644
--- a/phase1-wasm/Cargo.toml
+++ b/phase1-wasm/Cargo.toml
@@ -15,7 +15,7 @@ crate-type = ["cdylib", "rlib"]
 phase1 = { path = "../phase1", default-features = false }
 setup-utils = { path = "../setup-utils", default-features = false }
 
-zexe_algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra", features = ["bls12_377", "bw6_761", "derive"] }
+algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra", features = ["bls12_377", "bw6_761", "derive"] }
 
 rand = { version = "0.7" }
 serde = { version = "1.0.114" }
diff --git a/phase1-wasm/src/phase1.rs b/phase1-wasm/src/phase1.rs
index bf929d2..b2b899d 100644
--- a/phase1-wasm/src/phase1.rs
+++ b/phase1-wasm/src/phase1.rs
@@ -1,15 +1,12 @@
-use phase1::{
-    helpers::{curve_from_str, proving_system_from_str, CurveKind},
-    ContributionMode, Phase1, Phase1Parameters, ProvingSystem,
-};
+use phase1::{ContributionMode, Phase1, Phase1Parameters, ProvingSystem};
 use setup_utils::{
-    calculate_hash, derive_rng_from_seed, get_rng, user_system_randomness, BatchExpMode, CheckForCorrectness,
-    UseCompression,
+    calculate_hash,
+    converters::{batch_exp_mode_from_str, curve_from_str, proving_system_from_str, CurveKind},
+    derive_rng_from_seed, get_rng, user_system_randomness, BatchExpMode, CheckForCorrectness, UseCompression,
 };
 
-use zexe_algebra::{Bls12_377, PairingEngine, BW6_761};
+use algebra::{Bls12_377, PairingEngine, BW6_761};
 
-use phase1::helpers::batch_exp_mode_from_str;
 use rand::Rng;
 use wasm_bindgen::prelude::*;
 
diff --git a/phase1-wasm/src/tests.rs b/phase1-wasm/src/tests.rs
index c92d30c..53f89aa 100644
--- a/phase1-wasm/src/tests.rs
+++ b/phase1-wasm/src/tests.rs
@@ -2,7 +2,7 @@ use crate::phase1::*;
 use phase1::{ContributionMode, Phase1, Phase1Parameters, ProvingSystem};
 use setup_utils::{batch_exp, blank_hash, generate_powers_of_tau, BatchExpMode, UseCompression};
 
-use zexe_algebra::{batch_inversion, AffineCurve, Bls12_377, Field, PairingEngine, ProjectiveCurve, BW6_761};
+use algebra::{batch_inversion, AffineCurve, Bls12_377, Field, PairingEngine, ProjectiveCurve, BW6_761};
 
 use rand::SeedableRng;
 use rand_xorshift::XorShiftRng;
diff --git a/phase1/Cargo.toml b/phase1/Cargo.toml
index bc0a3a3..51d98ee 100644
--- a/phase1/Cargo.toml
+++ b/phase1/Cargo.toml
@@ -16,9 +16,9 @@ required-features = ["benchmark"]
 [dependencies]
 setup-utils = { path = "../setup-utils", default-features = false }
 
-zexe_algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra", features = ["derive"] }
-zexe_algebra_core = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra-core", optional = true, features = ["derive"] }
-zexe_fft = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "ff-fft", default-features = false }
+algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra", features = ["derive"] }
+algebra_core = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra-core", optional = true, features = ["derive"] }
+fft = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "ff-fft", default-features = false }
 
 cfg-if = { version = "0.1.10" }
 criterion = { version = "0.3", optional = true }
@@ -28,13 +28,13 @@ rayon = { version = "1.3.0", optional = true }
 tracing = { version = "0.1.17" }
 tracing-subscriber = { version = "0.2.3" }
 derivative = { version = "2", features = [ "use_core" ] }
-zexe_bench_utils = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "bench-utils" }
+bench_utils = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "bench-utils" }
 
 [dev-dependencies]
 phase1 = { path = "./", features = ["testing"] }
 
-zexe_algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra", features = ["full", "derive"] }
-zexe_r1cs_core = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "r1cs-core" }
+algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra", features = ["full", "derive"] }
+r1cs_core = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "r1cs-core" }
 marlin = { git = "https://github.com/scipr-lab/marlin", rev = "b7b4be4" }
 poly-commit = { git = "https://github.com/scipr-lab/poly-commit", rev = "efff1c1" }
 
@@ -46,11 +46,11 @@ rusty-hook = { version = "0.11.2" }
 [features]
 default = ["cli"]
 cli = ["parallel", "setup-utils/cli"]
-parallel = ["rayon", "setup-utils/parallel", "zexe_algebra/parallel", "zexe_algebra_core/parallel", "zexe_fft/parallel"]
+parallel = ["rayon", "setup-utils/parallel", "algebra/parallel", "algebra_core/parallel", "fft/parallel"]
 wasm = ["setup-utils/wasm"]
 
 benchmark = ["criterion"]
-testing = ["parallel", "zexe_algebra_core", "zexe_bench_utils/print-trace"]
+testing = ["parallel", "algebra_core", "bench_utils/print-trace"]
 
 [[test]]
 name = "marlin"
diff --git a/phase1/benches/phase1.rs b/phase1/benches/phase1.rs
index 850dafb..af0df9a 100644
--- a/phase1/benches/phase1.rs
+++ b/phase1/benches/phase1.rs
@@ -4,7 +4,7 @@ use phase1::{
 };
 use setup_utils::*;
 
-use zexe_algebra::Bls12_377;
+use algebra::Bls12_377;
 
 use criterion::{criterion_group, criterion_main, Criterion, Throughput};
 use rand::thread_rng;
diff --git a/phase1/src/aggregation.rs b/phase1/src/aggregation.rs
index bbd4493..2a8d765 100644
--- a/phase1/src/aggregation.rs
+++ b/phase1/src/aggregation.rs
@@ -357,7 +357,7 @@ mod tests {
     use super::*;
     use crate::helpers::testing::{generate_input, generate_new_challenge, generate_output};
 
-    use zexe_algebra::{Bls12_377, BW6_761};
+    use algebra::{Bls12_377, BW6_761};
 
     fn aggregation_test<E: PairingEngine>(
         powers: usize,
diff --git a/phase1/src/computation.rs b/phase1/src/computation.rs
index 21a7126..ace27fa 100644
--- a/phase1/src/computation.rs
+++ b/phase1/src/computation.rs
@@ -1,5 +1,5 @@
 use super::*;
-use zexe_algebra::{batch_inversion, Field};
+use algebra::{batch_inversion, Field};
 
 impl<'a, E: PairingEngine + Sync> Phase1<'a, E> {
     ///
@@ -311,7 +311,7 @@ mod tests {
     use crate::helpers::testing::generate_input;
     use setup_utils::{batch_exp, derive_rng_from_seed, generate_powers_of_tau};
 
-    use zexe_algebra::{Bls12_377, ProjectiveCurve, BW6_761};
+    use algebra::{Bls12_377, ProjectiveCurve, BW6_761};
 
     fn curve_computation_test<E: PairingEngine>(
         powers: usize,
diff --git a/phase1/src/helpers/accumulator.rs b/phase1/src/helpers/accumulator.rs
index c41270b..30aa3e1 100644
--- a/phase1/src/helpers/accumulator.rs
+++ b/phase1/src/helpers/accumulator.rs
@@ -4,12 +4,12 @@ use crate::{helpers::buffers::*, Phase1Parameters, ProvingSystem};
 use cfg_if::cfg_if;
 use setup_utils::{BatchDeserializer, BatchSerializer, Deserializer, Serializer, *};
 
-use zexe_algebra::{AffineCurve, PairingEngine};
+use algebra::{AffineCurve, PairingEngine};
 
 #[cfg(not(feature = "wasm"))]
 use setup_utils::SubgroupCheckMode;
 #[cfg(not(feature = "wasm"))]
-use {crate::ContributionMode, zexe_algebra::batch_verify_in_subgroup};
+use {crate::ContributionMode, algebra::batch_verify_in_subgroup};
 
 #[allow(type_alias_bounds)]
 type AccumulatorElements<E: PairingEngine> = (
@@ -32,7 +32,7 @@ type AccumulatorElementsRef<'a, E: PairingEngine> = (
 
 cfg_if! {
     if #[cfg(not(feature = "wasm"))] {
-        use zexe_algebra::{PrimeField, FpParameters, cfg_iter, Zero};
+        use algebra::{PrimeField, FpParameters, cfg_iter, Zero};
         #[cfg(feature = "parallel")]
         use rayon::prelude::*;
         use tracing::debug;
@@ -328,7 +328,7 @@ mod tests {
     use super::*;
     use crate::helpers::testing::random_point_vec;
 
-    use zexe_algebra::bls12_377::Bls12_377;
+    use algebra::bls12_377::Bls12_377;
 
     use rand::thread_rng;
 
diff --git a/phase1/src/helpers/buffers.rs b/phase1/src/helpers/buffers.rs
index dd0c87f..0cb8d7c 100644
--- a/phase1/src/helpers/buffers.rs
+++ b/phase1/src/helpers/buffers.rs
@@ -1,7 +1,7 @@
 use crate::{ContributionMode, Phase1Parameters, ProvingSystem};
 use setup_utils::{BatchDeserializer, BatchSerializer, *};
 
-use zexe_algebra::{AffineCurve, PairingEngine};
+use algebra::{AffineCurve, PairingEngine};
 
 use itertools::{Itertools, MinMaxResult};
 
diff --git a/phase1/src/helpers/mod.rs b/phase1/src/helpers/mod.rs
index 4d6f6ac..ff5ef0a 100644
--- a/phase1/src/helpers/mod.rs
+++ b/phase1/src/helpers/mod.rs
@@ -3,8 +3,5 @@ pub use accumulator::*;
 
 pub mod buffers;
 
-pub mod converters;
-pub use converters::*;
-
 #[cfg(feature = "testing")]
 pub mod testing;
diff --git a/phase1/src/helpers/testing.rs b/phase1/src/helpers/testing.rs
index 1a22c45..740406e 100644
--- a/phase1/src/helpers/testing.rs
+++ b/phase1/src/helpers/testing.rs
@@ -1,8 +1,8 @@
 use crate::{Phase1, Phase1Parameters, PublicKey};
 use setup_utils::*;
 
-use zexe_algebra::{AffineCurve, PairingEngine, ProjectiveCurve};
-use zexe_algebra_core::UniformRand;
+use algebra::{AffineCurve, PairingEngine, ProjectiveCurve};
+use algebra_core::UniformRand;
 
 use rand::{thread_rng, Rng};
 
diff --git a/phase1/src/initialization.rs b/phase1/src/initialization.rs
index aa02aec..35d5dd1 100644
--- a/phase1/src/initialization.rs
+++ b/phase1/src/initialization.rs
@@ -60,7 +60,7 @@ impl<'a, E: PairingEngine + Sync> Phase1<'a, E> {
 mod tests {
     use super::*;
 
-    use zexe_algebra::{AffineCurve, Bls12_377, BW6_761};
+    use algebra::{AffineCurve, Bls12_377, BW6_761};
 
     fn curve_initialization_test<E: PairingEngine>(powers: usize, batch: usize, compression: UseCompression) {
         for proving_system in &[ProvingSystem::Groth16, ProvingSystem::Marlin] {
diff --git a/phase1/src/lib.rs b/phase1/src/lib.rs
index 7a02560..f1165a9 100644
--- a/phase1/src/lib.rs
+++ b/phase1/src/lib.rs
@@ -3,6 +3,8 @@ pub mod helpers;
 pub mod objects;
 pub use objects::*;
 
+pub use setup_utils::converters::{ContributionMode, ProvingSystem};
+
 #[cfg(not(feature = "wasm"))]
 mod aggregation;
 mod computation;
@@ -22,9 +24,9 @@ use setup_utils::*;
 use crate::helpers::accumulator::*;
 
 #[cfg(not(feature = "wasm"))]
-use zexe_algebra::Zero;
+use algebra::Zero;
 
-use zexe_algebra::{AffineCurve, PairingEngine, ProjectiveCurve, UniformRand};
+use algebra::{AffineCurve, PairingEngine, ProjectiveCurve, UniformRand};
 
 use rand::Rng;
 use tracing::{debug, info, info_span, trace};
diff --git a/phase1/src/objects/parameters.rs b/phase1/src/objects/parameters.rs
index bf24769..cb0bea4 100644
--- a/phase1/src/objects/parameters.rs
+++ b/phase1/src/objects/parameters.rs
@@ -1,21 +1,12 @@
-use setup_utils::UseCompression;
+use setup_utils::{
+    converters::{ContributionMode, ProvingSystem},
+    UseCompression,
+};
 
-use zexe_algebra::{ConstantSerializedSize, PairingEngine};
+use algebra::{ConstantSerializedSize, PairingEngine};
 
 use std::marker::PhantomData;
 
-#[derive(Clone, PartialEq, Eq, Debug, Copy)]
-pub enum ContributionMode {
-    Full,
-    Chunked,
-}
-
-#[derive(Clone, Copy, PartialEq, Eq, Debug)]
-pub enum ProvingSystem {
-    Groth16,
-    Marlin,
-}
-
 /// The sizes of the group elements of a curve
 #[derive(Clone, PartialEq, Eq, Default, Debug)]
 pub struct CurveParameters<E> {
@@ -304,7 +295,7 @@ impl<E: PairingEngine> Phase1Parameters<E> {
 #[cfg(test)]
 mod tests {
     use super::*;
-    use zexe_algebra::{Bls12_377, Bls12_381, BW6_761};
+    use algebra::{Bls12_377, Bls12_381, BW6_761};
 
     fn curve_parameters_test<E: PairingEngine>(g1: usize, g2: usize, g1_compressed: usize, g2_compressed: usize) {
         let p = CurveParameters::<E>::new();
diff --git a/phase1/src/objects/private_key.rs b/phase1/src/objects/private_key.rs
index 85aded2..3fc533f 100644
--- a/phase1/src/objects/private_key.rs
+++ b/phase1/src/objects/private_key.rs
@@ -1,4 +1,4 @@
-use zexe_algebra::PairingEngine;
+use algebra::PairingEngine;
 
 /// Contains the secrets τ, α and β that the participant of the ceremony must destroy.
 #[derive(PartialEq, Debug)]
diff --git a/phase1/src/objects/public_key.rs b/phase1/src/objects/public_key.rs
index bcd914f..2fd1f8c 100644
--- a/phase1/src/objects/public_key.rs
+++ b/phase1/src/objects/public_key.rs
@@ -1,7 +1,7 @@
 use crate::Phase1Parameters;
 use setup_utils::{Error, UseCompression};
 
-use zexe_algebra::{CanonicalDeserialize, CanonicalSerialize, PairingEngine, SerializationError};
+use algebra::{CanonicalDeserialize, CanonicalSerialize, PairingEngine, SerializationError};
 
 use std::io::{Read, Write};
 
diff --git a/phase1/src/serialization.rs b/phase1/src/serialization.rs
index 99fb80b..3008584 100644
--- a/phase1/src/serialization.rs
+++ b/phase1/src/serialization.rs
@@ -56,7 +56,7 @@ mod tests {
     use super::*;
     use crate::helpers::testing::{generate_output, generate_random_accumulator};
 
-    use zexe_algebra::{Bls12_377, BW6_761};
+    use algebra::{Bls12_377, BW6_761};
 
     fn serialize_curve_test<E: PairingEngine + Sync>(compress: UseCompression, size: usize, batch: usize) {
         for proving_system in &[ProvingSystem::Groth16, ProvingSystem::Marlin] {
diff --git a/phase1/src/verification.rs b/phase1/src/verification.rs
index e6edcb4..859b447 100644
--- a/phase1/src/verification.rs
+++ b/phase1/src/verification.rs
@@ -676,7 +676,7 @@ mod tests {
     use crate::helpers::testing::{generate_input, generate_new_challenge, generate_output};
     use setup_utils::calculate_hash;
 
-    use zexe_algebra::{Bls12_377, BW6_761};
+    use algebra::{Bls12_377, BW6_761};
 
     fn full_verification_test<E: PairingEngine>(
         total_size_in_log2: usize,
diff --git a/phase1/tests/marlin.rs b/phase1/tests/marlin.rs
index f3fc8e3..236a055 100644
--- a/phase1/tests/marlin.rs
+++ b/phase1/tests/marlin.rs
@@ -5,13 +5,13 @@ mod test {
     use rand::thread_rng;
     use setup_utils::{blank_hash, BatchExpMode, CheckForCorrectness, UseCompression};
 
+    use algebra::{bls12_377::Fr, Bls12_377, Field, UniformRand};
     use blake2::Blake2s;
     use itertools::Itertools;
     use marlin::Marlin;
     use poly_commit::sonic_pc::SonicKZG10;
+    use r1cs_core::{lc, ConstraintSynthesizer, ConstraintSystemRef, SynthesisError};
     use std::{collections::BTreeMap, ops::MulAssign};
-    use zexe_algebra::{bls12_377::Fr, Bls12_377, Field, UniformRand};
-    use zexe_r1cs_core::{lc, ConstraintSynthesizer, ConstraintSystemRef, SynthesisError};
 
     #[derive(Copy, Clone)]
     struct Circuit<F: Field> {
diff --git a/phase2-cli/Cargo.toml b/phase2-cli/Cargo.toml
new file mode 100644
index 0000000..6ee7bbb
--- /dev/null
+++ b/phase2-cli/Cargo.toml
@@ -0,0 +1,45 @@
+[package]
+name = "phase2-cli"
+version = "0.3.0"
+authors = ["Kobi Gurkan <kobigurk@gmail.com>"]
+description = "CLI implementation of Phase 2"
+homepage = "https://github.com/celo-org/snark-setup"
+repository = "https://github.com/celo-org/snark-setup"
+license = "MIT/Apache-2.0"
+edition = "2018"
+
+[dependencies]
+phase2 = { path = "../phase2", default-features = false }
+setup-utils = { path = "../setup-utils", default-features = false }
+
+algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra", features = ["bls12_377", "bw6_761", "derive"] }
+r1cs_core = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "r1cs-core" }
+groth16 = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "groth16", features = [] }
+bench-utils = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "bench-utils", features = [] }
+
+gumdrop = { version = "0.7.0" }
+hex = { version = "0.4.2" }
+memmap = { version = "0.7.0" }
+rand = { version = "0.7" }
+tracing = { version = "0.1.17" }
+tracing-subscriber = { version = "0.2.3" }
+phase1 = { path = "../phase1" }
+epoch-snark = { git = "https://github.com/celo-org/celo-bls-snark-rs" }
+
+[dev-dependencies]
+rand_xorshift = { version = "0.2" }
+wasm-bindgen-test = { version = "0.3.15" }
+
+[build-dependencies]
+rustc_version = { version = "0.2" }
+
+[features]
+default = ["cli", "bw6_asm"]
+cli = ["phase2/cli", "parallel", "setup-utils/cli", "phase1/cli"]
+parallel = ["setup-utils/parallel", "algebra/parallel", "phase2/parallel", "phase1/parallel"]
+bw6_asm = [ "algebra/bw6_asm" ]
+
+[[bin]]
+name = "phase2"
+required-features = ["cli"]
+
diff --git a/phase2-cli/LICENSE-APACHE b/phase2-cli/LICENSE-APACHE
new file mode 100644
index 0000000..16fe87b
--- /dev/null
+++ b/phase2-cli/LICENSE-APACHE
@@ -0,0 +1,201 @@
+                              Apache License
+                        Version 2.0, January 2004
+                     http://www.apache.org/licenses/
+
+TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+1. Definitions.
+
+   "License" shall mean the terms and conditions for use, reproduction,
+   and distribution as defined by Sections 1 through 9 of this document.
+
+   "Licensor" shall mean the copyright owner or entity authorized by
+   the copyright owner that is granting the License.
+
+   "Legal Entity" shall mean the union of the acting entity and all
+   other entities that control, are controlled by, or are under common
+   control with that entity. For the purposes of this definition,
+   "control" means (i) the power, direct or indirect, to cause the
+   direction or management of such entity, whether by contract or
+   otherwise, or (ii) ownership of fifty percent (50%) or more of the
+   outstanding shares, or (iii) beneficial ownership of such entity.
+
+   "You" (or "Your") shall mean an individual or Legal Entity
+   exercising permissions granted by this License.
+
+   "Source" form shall mean the preferred form for making modifications,
+   including but not limited to software source code, documentation
+   source, and configuration files.
+
+   "Object" form shall mean any form resulting from mechanical
+   transformation or translation of a Source form, including but
+   not limited to compiled object code, generated documentation,
+   and conversions to other media types.
+
+   "Work" shall mean the work of authorship, whether in Source or
+   Object form, made available under the License, as indicated by a
+   copyright notice that is included in or attached to the work
+   (an example is provided in the Appendix below).
+
+   "Derivative Works" shall mean any work, whether in Source or Object
+   form, that is based on (or derived from) the Work and for which the
+   editorial revisions, annotations, elaborations, or other modifications
+   represent, as a whole, an original work of authorship. For the purposes
+   of this License, Derivative Works shall not include works that remain
+   separable from, or merely link (or bind by name) to the interfaces of,
+   the Work and Derivative Works thereof.
+
+   "Contribution" shall mean any work of authorship, including
+   the original version of the Work and any modifications or additions
+   to that Work or Derivative Works thereof, that is intentionally
+   submitted to Licensor for inclusion in the Work by the copyright owner
+   or by an individual or Legal Entity authorized to submit on behalf of
+   the copyright owner. For the purposes of this definition, "submitted"
+   means any form of electronic, verbal, or written communication sent
+   to the Licensor or its representatives, including but not limited to
+   communication on electronic mailing lists, source code control systems,
+   and issue tracking systems that are managed by, or on behalf of, the
+   Licensor for the purpose of discussing and improving the Work, but
+   excluding communication that is conspicuously marked or otherwise
+   designated in writing by the copyright owner as "Not a Contribution."
+
+   "Contributor" shall mean Licensor and any individual or Legal Entity
+   on behalf of whom a Contribution has been received by Licensor and
+   subsequently incorporated within the Work.
+
+2. Grant of Copyright License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   copyright license to reproduce, prepare Derivative Works of,
+   publicly display, publicly perform, sublicense, and distribute the
+   Work and such Derivative Works in Source or Object form.
+
+3. Grant of Patent License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   (except as stated in this section) patent license to make, have made,
+   use, offer to sell, sell, import, and otherwise transfer the Work,
+   where such license applies only to those patent claims licensable
+   by such Contributor that are necessarily infringed by their
+   Contribution(s) alone or by combination of their Contribution(s)
+   with the Work to which such Contribution(s) was submitted. If You
+   institute patent litigation against any entity (including a
+   cross-claim or counterclaim in a lawsuit) alleging that the Work
+   or a Contribution incorporated within the Work constitutes direct
+   or contributory patent infringement, then any patent licenses
+   granted to You under this License for that Work shall terminate
+   as of the date such litigation is filed.
+
+4. Redistribution. You may reproduce and distribute copies of the
+   Work or Derivative Works thereof in any medium, with or without
+   modifications, and in Source or Object form, provided that You
+   meet the following conditions:
+
+   (a) You must give any other recipients of the Work or
+       Derivative Works a copy of this License; and
+
+   (b) You must cause any modified files to carry prominent notices
+       stating that You changed the files; and
+
+   (c) You must retain, in the Source form of any Derivative Works
+       that You distribute, all copyright, patent, trademark, and
+       attribution notices from the Source form of the Work,
+       excluding those notices that do not pertain to any part of
+       the Derivative Works; and
+
+   (d) If the Work includes a "NOTICE" text file as part of its
+       distribution, then any Derivative Works that You distribute must
+       include a readable copy of the attribution notices contained
+       within such NOTICE file, excluding those notices that do not
+       pertain to any part of the Derivative Works, in at least one
+       of the following places: within a NOTICE text file distributed
+       as part of the Derivative Works; within the Source form or
+       documentation, if provided along with the Derivative Works; or,
+       within a display generated by the Derivative Works, if and
+       wherever such third-party notices normally appear. The contents
+       of the NOTICE file are for informational purposes only and
+       do not modify the License. You may add Your own attribution
+       notices within Derivative Works that You distribute, alongside
+       or as an addendum to the NOTICE text from the Work, provided
+       that such additional attribution notices cannot be construed
+       as modifying the License.
+
+   You may add Your own copyright statement to Your modifications and
+   may provide additional or different license terms and conditions
+   for use, reproduction, or distribution of Your modifications, or
+   for any such Derivative Works as a whole, provided Your use,
+   reproduction, and distribution of the Work otherwise complies with
+   the conditions stated in this License.
+
+5. Submission of Contributions. Unless You explicitly state otherwise,
+   any Contribution intentionally submitted for inclusion in the Work
+   by You to the Licensor shall be under the terms and conditions of
+   this License, without any additional terms or conditions.
+   Notwithstanding the above, nothing herein shall supersede or modify
+   the terms of any separate license agreement you may have executed
+   with Licensor regarding such Contributions.
+
+6. Trademarks. This License does not grant permission to use the trade
+   names, trademarks, service marks, or product names of the Licensor,
+   except as required for reasonable and customary use in describing the
+   origin of the Work and reproducing the content of the NOTICE file.
+
+7. Disclaimer of Warranty. Unless required by applicable law or
+   agreed to in writing, Licensor provides the Work (and each
+   Contributor provides its Contributions) on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+   implied, including, without limitation, any warranties or conditions
+   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+   PARTICULAR PURPOSE. You are solely responsible for determining the
+   appropriateness of using or redistributing the Work and assume any
+   risks associated with Your exercise of permissions under this License.
+
+8. Limitation of Liability. In no event and under no legal theory,
+   whether in tort (including negligence), contract, or otherwise,
+   unless required by applicable law (such as deliberate and grossly
+   negligent acts) or agreed to in writing, shall any Contributor be
+   liable to You for damages, including any direct, indirect, special,
+   incidental, or consequential damages of any character arising as a
+   result of this License or out of the use or inability to use the
+   Work (including but not limited to damages for loss of goodwill,
+   work stoppage, computer failure or malfunction, or any and all
+   other commercial damages or losses), even if such Contributor
+   has been advised of the possibility of such damages.
+
+9. Accepting Warranty or Additional Liability. While redistributing
+   the Work or Derivative Works thereof, You may choose to offer,
+   and charge a fee for, acceptance of support, warranty, indemnity,
+   or other liability obligations and/or rights consistent with this
+   License. However, in accepting such obligations, You may act only
+   on Your own behalf and on Your sole responsibility, not on behalf
+   of any other Contributor, and only if You agree to indemnify,
+   defend, and hold each Contributor harmless for any liability
+   incurred by, or claims asserted against, such Contributor by reason
+   of your accepting any such warranty or additional liability.
+
+END OF TERMS AND CONDITIONS
+
+APPENDIX: How to apply the Apache License to your work.
+
+   To apply the Apache License to your work, attach the following
+   boilerplate notice, with the fields enclosed by brackets "[]"
+   replaced with your own identifying information. (Don't include
+   the brackets!)  The text should be enclosed in the appropriate
+   comment syntax for the file format. We also recommend that a
+   file or class name and description of purpose be included on the
+   same "printed page" as the copyright notice for easier
+   identification within third-party archives.
+
+Copyright [yyyy] [name of copyright owner]
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+	http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff --git a/phase2-cli/LICENSE-MIT b/phase2-cli/LICENSE-MIT
new file mode 100644
index 0000000..31aa793
--- /dev/null
+++ b/phase2-cli/LICENSE-MIT
@@ -0,0 +1,23 @@
+Permission is hereby granted, free of charge, to any
+person obtaining a copy of this software and associated
+documentation files (the "Software"), to deal in the
+Software without restriction, including without
+limitation the rights to use, copy, modify, merge,
+publish, distribute, sublicense, and/or sell copies of
+the Software, and to permit persons to whom the Software
+is furnished to do so, subject to the following
+conditions:
+
+The above copyright notice and this permission notice
+shall be included in all copies or substantial portions
+of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF
+ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED
+TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
+PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT
+SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
+CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR
+IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+DEALINGS IN THE SOFTWARE.
diff --git a/phase2-cli/README.md b/phase2-cli/README.md
new file mode 100644
index 0000000..5e94132
--- /dev/null
+++ b/phase2-cli/README.md
@@ -0,0 +1,71 @@
+# Phase 1 CLI
+
+You can see an E2E demo with 3 participants and the beacon at the end by running `test.sh`.
+
+## CLI Guide
+
+### Phase 1
+
+Coordinators run:
+1. `new` to create a new accumulator
+1. `verify-and-transform` after receiving a contribution to the previous challenge, to produce a new challenge for the next contribution
+1. `beacon` at the end of the ceremony (optional, as the security proof [does not require it](https://electriccoin.co/blog/reinforcing-the-security-of-the-sapling-mpc/))
+
+Users should only care about the `contribute` option.
+
+```ignore
+$ ./phase1 --help
+Usage: ./phase1 [OPTIONS]
+
+Optional arguments:
+  -h, --help
+  -c, --curve-kind CURVE-KIND
+                     the elliptic curve to use (default: bls12_381)
+  -p, --proving-system PROVING-SYSTEM
+                     the proving system to use (default: groth16)
+  -b, --batch-size BATCH-SIZE
+                     the size of batches to process (default: 256)
+  -P, --power POWER  the circuit power (circuit size will be 2^{power}) (default: 21)
+
+Available commands:
+
+  new                   creates a new challenge for the ceremony
+  contribute            contribute to ceremony by producing a response to a challenge (or create a new challenge if this is the first contribution)
+  beacon                contribute randomness via a random beacon (e.g. a bitcoin block header hash)
+  verify-and-transform  verify the contributions so far and generate a new challenge
+```
+
+### Prepare Phase 2
+
+This binary will only be run by the coordinator after Phase 1 has been executed.
+Note that the parameters produced are **only for the Groth16 SNARK**.
+
+```ignore
+./prepare_phase2 --help
+Usage: ./prepare_phase2 [OPTIONS]
+
+Optional arguments:
+  -h, --help
+  -p, --phase2-fname PHASE2-FNAME
+                             the file which will contain the FFT coefficients processed for Phase 2 of the setup
+  -r, --response-fname RESPONSE-FNAME
+                             the response file which will be processed for the specialization (phase 2) of the setup
+  -c, --curve-kind CURVE-KIND
+                             the elliptic curve to use (default: bls12_377)
+  -P, --proving-system PROVING-SYSTEM
+                             the proving system to use (default: groth16)
+  -b, --batch-size BATCH-SIZE
+                             the size of batches to process (default: 256)
+  --power POWER              the number of powers used for phase 1 (circuit size will be 2^{power}) (default: 21)
+  --phase2-size PHASE2-SIZE  the size of the phase 2 circuit (default: 21
+```
+
+## License
+
+This work is licensed under either of the following licenses, at your discretion.
+
+- Apache License Version 2.0 (LICENSE-APACHE or http://www.apache.org/licenses/LICENSE-2.0)
+- MIT license (LICENSE-MIT or http://opensource.org/licenses/MIT)
+
+Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you,
+as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.
diff --git a/phase2-cli/build.rs b/phase2-cli/build.rs
new file mode 100644
index 0000000..a5ba889
--- /dev/null
+++ b/phase2-cli/build.rs
@@ -0,0 +1,12 @@
+// Detect the rustc channel
+use rustc_version::{version_meta, Channel};
+
+fn main() {
+    // Set cfg flags depending on release channel
+    match version_meta().unwrap().channel {
+        Channel::Stable => println!("cargo:rustc-cfg=stable"),
+        Channel::Beta => println!("cargo:rustc-cfg=beta"),
+        Channel::Nightly => println!("cargo:rustc-cfg=nightly"),
+        Channel::Dev => println!("cargo:rustc-cfg=rustc_dev"),
+    }
+}
diff --git a/phase2-cli/scripts/phase2_chunked.sh b/phase2-cli/scripts/phase2_chunked.sh
new file mode 100755
index 0000000..356147a
--- /dev/null
+++ b/phase2-cli/scripts/phase2_chunked.sh
@@ -0,0 +1,61 @@
+#!/bin/bash -e
+
+rm -f challenge* response* new_challenge* new_response* new_new_challenge_* processed* initial_ceremony* response_list* combined* seed* chunk*
+
+export RUSTFLAGS="-C target-feature=+bmi2,+adx"
+CARGO_VER=""
+PROVING_SYSTEM=groth16
+POWER=18
+BATCH=131072
+CHUNK_SIZE=131072
+CURVE="bw6"
+SEED1=$(tr -dc 'A-F0-9' < /dev/urandom | head -c32)
+echo $SEED1 > seed1
+SEED2=$(tr -dc 'A-F0-9' < /dev/urandom | head -c32)
+echo $SEED2 > seed2
+
+function check_hash() {
+  test "`xxd -p -c 64 $1.hash`" = "`b2sum $1 | awk '{print $1}'`"
+}
+
+cargo $CARGO_VER build --release --bin phase2
+
+phase2_chunked="../../target/release/phase2 --curve-kind $CURVE --chunk-size $CHUNK_SIZE --batch-size $BATCH --contribution-mode full --proving-system $PROVING_SYSTEM"
+phase2_1="../../target/release/phase2 --curve-kind $CURVE --batch-size $BATCH --contribution-mode chunked --chunk-size $CHUNK_SIZE --seed seed1 --proving-system $PROVING_SYSTEM"
+phase2_2="../../target/release/phase2 --curve-kind $CURVE --batch-size $BATCH --contribution-mode chunked --chunk-size $CHUNK_SIZE --seed seed2 --proving-system $PROVING_SYSTEM"
+####### Phase 2
+
+MAX_CHUNK_INDEX=1
+
+$phase2_chunked new --challenge-fname challenge --challenge-hash-fname challenge.verified.hash --phase1-fname ../../phase1-tests/phase1 --phase1-powers $POWER --num-validators 1 --num-epochs 1
+for i in $(seq 0 $(($MAX_CHUNK_INDEX/2))); do
+  echo "Contributing and verifying chunk $i..."
+  $phase2_1 --chunk-index $i contribute --challenge-fname challenge.$i --challenge-hash-fname challenge.$i.hash --response-fname response_$i --response-hash-fname response_$i.hash
+  check_hash challenge.$i
+  check_hash response_$i
+  $phase2_1 --chunk-index $i verify --challenge-fname challenge.$i --challenge-hash-fname challenge_$i.verified.hash --response-fname response_$i --response-hash-fname response_$i.verified.hash
+  rm response_$i.hash
+  $phase2_2 --chunk-index $i contribute --challenge-fname response_$i --challenge-hash-fname response_$i.hash --response-fname new_response_$i --response-hash-fname new_response_$i.hash
+  check_hash new_response_$i
+  $phase2_2 --chunk-index $i verify --challenge-fname response_$i  --challenge-hash-fname response_$i.verified.hash --response-fname new_response_$i --response-hash-fname new_response_$i.verified.hash
+  rm challenge.$i response_$i # no longer needed
+  echo new_response_$i >> response_list
+done
+
+for i in $(seq $(($MAX_CHUNK_INDEX/2 + 1)) $MAX_CHUNK_INDEX); do
+  echo "Contributing and verifying chunk $i..."
+  $phase2_2 --chunk-index $i contribute --challenge-fname challenge.$i --challenge-hash-fname challenge.$i.hash --response-fname response_$i --response-hash-fname response_$i.hash
+  check_hash challenge.$i
+  check_hash response_$i
+  $phase2_2 --chunk-index $i verify --challenge-fname challenge.$i --challenge-hash-fname challenge_$i.verified.hash --response-fname response_$i --response-hash-fname response_$i.verified.hash
+  rm response_$i.hash
+  $phase2_1 --chunk-index $i contribute --challenge-fname response_$i --challenge-hash-fname response_$i.hash --response-fname new_response_$i --response-hash-fname new_response_$i.hash
+  check_hash new_response_$i
+  $phase2_1 --chunk-index $i verify --challenge-fname response_$i  --challenge-hash-fname response_$i.verified.hash --response-fname new_response_$i --response-hash-fname new_response_$i.verified.hash
+  rm challenge.$i response_$i # no longer needed
+  echo new_response_$i >> response_list
+done
+
+$phase2_chunked combine --response-list-fname response_list --initial-query-fname challenge.query --initial-full-fname challenge.full --combined-fname combined
+
+echo "Done!"
\ No newline at end of file
diff --git a/phase2-cli/src/bin/phase2.rs b/phase2-cli/src/bin/phase2.rs
new file mode 100644
index 0000000..711ff7e
--- /dev/null
+++ b/phase2-cli/src/bin/phase2.rs
@@ -0,0 +1,95 @@
+use setup_utils::converters::CurveKind;
+
+use algebra::{Bls12_377, PairingEngine as Engine, BW6_761};
+
+use gumdrop::Options;
+use phase2_cli::{combine, contribute, new_challenge, verify, Command, Phase2Opts};
+use setup_utils::{
+    derive_rng_from_seed, upgrade_correctness_check_config, CheckForCorrectness,
+    DEFAULT_CONTRIBUTE_CHECK_INPUT_CORRECTNESS, DEFAULT_VERIFY_CHECK_INPUT_CORRECTNESS,
+};
+use std::fs::read_to_string;
+use std::{process, time::Instant};
+use tracing::{error, info};
+use tracing_subscriber::{
+    filter::EnvFilter,
+    fmt::{time::ChronoUtc, Subscriber},
+};
+
+fn execute_cmd<E: Engine>(opts: Phase2Opts) {
+    let command = opts.clone().command.unwrap_or_else(|| {
+        error!("No command was provided.");
+        error!("{}", Phase2Opts::usage());
+        process::exit(2)
+    });
+
+    let now = Instant::now();
+
+    match command {
+        Command::New(opt) => {
+            new_challenge(
+                &opt.challenge_fname,
+                &opt.challenge_hash_fname,
+                opts.chunk_size,
+                &opt.phase1_fname,
+                opt.phase1_powers,
+                opt.num_validators,
+                opt.num_epochs,
+            );
+        }
+        Command::Contribute(opt) => {
+            let seed = hex::decode(&read_to_string(&opts.seed).expect("should have read seed").trim())
+                .expect("seed should be a hex string");
+            let rng = derive_rng_from_seed(&seed);
+            contribute(
+                &opt.challenge_fname,
+                &opt.challenge_hash_fname,
+                &opt.response_fname,
+                &opt.response_hash_fname,
+                upgrade_correctness_check_config(
+                    DEFAULT_CONTRIBUTE_CHECK_INPUT_CORRECTNESS,
+                    opts.force_correctness_checks,
+                ),
+                opts.batch_exp_mode,
+                rng,
+            );
+        }
+        Command::Verify(opt) => {
+            verify(
+                &opt.challenge_fname,
+                &opt.challenge_hash_fname,
+                DEFAULT_VERIFY_CHECK_INPUT_CORRECTNESS,
+                &opt.response_fname,
+                &opt.response_hash_fname,
+                CheckForCorrectness::OnlyNonZero,
+                opts.subgroup_check_mode,
+            );
+        }
+        Command::Combine(opt) => {
+            combine(
+                &opt.initial_query_fname,
+                &opt.initial_full_fname,
+                &opt.response_list_fname,
+                &opt.combined_fname,
+            );
+        }
+    };
+
+    let new_now = Instant::now();
+    info!("Executing {:?} took: {:?}", opts, new_now.duration_since(now));
+}
+
+fn main() {
+    Subscriber::builder()
+        .with_target(false)
+        .with_timer(ChronoUtc::rfc3339())
+        .with_env_filter(EnvFilter::from_default_env())
+        .init();
+
+    let opts: Phase2Opts = Phase2Opts::parse_args_default_or_exit();
+
+    match opts.curve_kind {
+        CurveKind::Bls12_377 => execute_cmd::<Bls12_377>(opts),
+        CurveKind::BW6 => execute_cmd::<BW6_761>(opts),
+    };
+}
diff --git a/phase2-cli/src/combine.rs b/phase2-cli/src/combine.rs
new file mode 100644
index 0000000..a83a0f3
--- /dev/null
+++ b/phase2-cli/src/combine.rs
@@ -0,0 +1,85 @@
+use phase2::parameters::MPCParameters;
+use setup_utils::{print_hash, CheckForCorrectness, SubgroupCheckMode, UseCompression};
+
+use algebra::{CanonicalSerialize, BW6_761};
+
+use std::fs::File;
+use std::io::{BufRead, BufReader};
+use tracing::info;
+
+const INITIAL_IS_COMPRESSED: UseCompression = UseCompression::No;
+const CONTRIBUTION_IS_COMPRESSED: UseCompression = UseCompression::No;
+const COMBINED_IS_COMPRESSED: UseCompression = UseCompression::No;
+
+pub fn combine(
+    initial_query_filename: &str,
+    initial_full_filename: &str,
+    response_list_filename: &str,
+    combined_filename: &str,
+) {
+    info!("Combining phase 2");
+
+    let response_list_reader =
+        BufReader::new(File::open(response_list_filename).expect("should have opened the response list"));
+
+    let full_contents = std::fs::read(initial_full_filename).expect("should have initial full parameters");
+    let full_parameters = MPCParameters::<BW6_761>::read_fast(
+        full_contents.as_slice(),
+        INITIAL_IS_COMPRESSED,
+        CheckForCorrectness::No,
+        false,
+        SubgroupCheckMode::Auto,
+    )
+    .expect("should have read full parameters");
+
+    let mut query_contents =
+        std::io::Cursor::new(std::fs::read(initial_query_filename).expect("should have read initial query"));
+    let query_parameters = MPCParameters::<BW6_761>::read_groth16_fast(
+        &mut query_contents,
+        INITIAL_IS_COMPRESSED,
+        CheckForCorrectness::No,
+        false,
+        SubgroupCheckMode::Auto,
+    )
+    .expect("should have deserialized initial query params");
+
+    let mut all_parameters = vec![];
+    for line in response_list_reader.lines() {
+        let line = line.expect("should have read line");
+        let contents = std::fs::read(line).expect("should have read response");
+        let parameters = MPCParameters::<BW6_761>::read_fast(
+            contents.as_slice(),
+            CONTRIBUTION_IS_COMPRESSED,
+            CheckForCorrectness::No,
+            false,
+            SubgroupCheckMode::Auto,
+        )
+        .expect("should have read parameters");
+        all_parameters.push(parameters);
+    }
+
+    let combined =
+        MPCParameters::<BW6_761>::combine(&query_parameters, &all_parameters).expect("should have combined parameters");
+
+    let contributions_hash = full_parameters
+        .verify(&combined)
+        .expect("should have verified successfully");
+    info!("Contributions hashes:");
+    for contribution_hash in contributions_hash {
+        print_hash(&contribution_hash[..]);
+    }
+
+    let mut combined_contents = vec![];
+    combined
+        .write(&mut combined_contents, COMBINED_IS_COMPRESSED)
+        .expect("should have written combined");
+    std::fs::write(combined_filename, &combined_contents).expect("should have written combined file");
+
+    let mut combined_parameters_contents = vec![];
+    combined
+        .params
+        .serialize_uncompressed(&mut combined_parameters_contents)
+        .expect("should have serialized combined parameters");
+    std::fs::write(format!("{}.params", combined_filename), &combined_parameters_contents)
+        .expect("should have written combined parameters file");
+}
diff --git a/phase2-cli/src/contribute.rs b/phase2-cli/src/contribute.rs
new file mode 100644
index 0000000..7b33ba8
--- /dev/null
+++ b/phase2-cli/src/contribute.rs
@@ -0,0 +1,64 @@
+use phase2::parameters::MPCParameters;
+use setup_utils::{calculate_hash, print_hash, BatchExpMode, CheckForCorrectness, SubgroupCheckMode, UseCompression};
+
+use algebra::BW6_761;
+
+use rand::Rng;
+use std::io::Write;
+use tracing::info;
+
+const COMPRESSED_INPUT: UseCompression = UseCompression::No;
+const COMPRESSED_OUTPUT: UseCompression = UseCompression::No;
+
+pub fn contribute(
+    challenge_filename: &str,
+    challenge_hash_filename: &str,
+    response_filename: &str,
+    response_hash_filename: &str,
+    check_input_correctness: CheckForCorrectness,
+    batch_exp_mode: BatchExpMode,
+    mut rng: impl Rng,
+) {
+    info!("Contributing to phase 2");
+
+    let challenge_contents = std::fs::read(challenge_filename).expect("should have read challenge");
+    let challenge_hash = calculate_hash(&challenge_contents);
+    std::fs::File::create(challenge_hash_filename)
+        .expect("unable to open current accumulator hash file")
+        .write_all(&challenge_hash)
+        .expect("unable to write current accumulator hash");
+
+    info!("`challenge` file contains decompressed points and has a hash:");
+    print_hash(&challenge_hash);
+
+    let mut parameters = MPCParameters::<BW6_761>::read_fast(
+        challenge_contents.as_slice(),
+        COMPRESSED_INPUT,
+        check_input_correctness,
+        false,
+        SubgroupCheckMode::Auto,
+    )
+    .expect("should have read parameters");
+    parameters
+        .contribute(batch_exp_mode, &mut rng)
+        .expect("should have successfully contributed");
+    let mut serialized_response = vec![];
+    parameters
+        .write(&mut serialized_response, COMPRESSED_OUTPUT)
+        .expect("should have written input");
+    std::fs::File::create(response_filename)
+        .expect("unable to create response")
+        .write_all(&serialized_response)
+        .expect("unable to write the response");
+    let response_hash = calculate_hash(&serialized_response);
+    std::fs::File::create(response_hash_filename)
+        .expect("unable to create response hash")
+        .write_all(&response_hash)
+        .expect("unable to write the response hash");
+    info!(
+        "Done!\n\n\
+              Your contribution has been written to response file\n\n\
+              The BLAKE2b hash of response file is:\n"
+    );
+    print_hash(&response_hash);
+}
diff --git a/phase2-cli/src/lib.rs b/phase2-cli/src/lib.rs
new file mode 100644
index 0000000..788fe6f
--- /dev/null
+++ b/phase2-cli/src/lib.rs
@@ -0,0 +1,154 @@
+// Documentation
+#![cfg_attr(nightly, feature(doc_cfg, external_doc))]
+#![cfg_attr(nightly, doc(include = "../README.md"))]
+
+mod new_challenge;
+pub use new_challenge::new_challenge;
+
+mod contribute;
+pub use contribute::contribute;
+
+mod verify;
+pub use verify::verify;
+
+mod combine;
+pub use combine::combine;
+
+use setup_utils::converters::{ContributionMode, CurveKind, ProvingSystem};
+
+use gumdrop::Options;
+use setup_utils::{
+    converters::{
+        batch_exp_mode_from_str, contribution_mode_from_str, curve_from_str, proving_system_from_str,
+        subgroup_check_mode_from_str,
+    },
+    BatchExpMode, SubgroupCheckMode,
+};
+use std::default::Default;
+
+#[derive(Debug, Options, Clone)]
+pub struct Phase2Opts {
+    help: bool,
+    #[options(help = "the seed to derive private elements from")]
+    pub seed: String,
+    #[options(
+        help = "the contribution mode",
+        default = "chunked",
+        parse(try_from_str = "contribution_mode_from_str")
+    )]
+    pub contribution_mode: ContributionMode,
+    #[options(help = "the chunk index to process")]
+    pub chunk_index: usize,
+    #[options(help = "the chunk size")]
+    pub chunk_size: usize,
+    #[options(
+        help = "the elliptic curve to use",
+        default = "bls12_377",
+        parse(try_from_str = "curve_from_str")
+    )]
+    pub curve_kind: CurveKind,
+    #[options(
+        help = "the proving system to use",
+        default = "groth16",
+        parse(try_from_str = "proving_system_from_str")
+    )]
+    pub proving_system: ProvingSystem,
+    #[options(help = "the size of batches to process", default = "16384")]
+    pub batch_size: usize,
+    #[options(command)]
+    pub command: Option<Command>,
+    #[options(
+        help = "whether to always check whether incoming challenges are in correct subgroup and non-zero",
+        default = "false"
+    )]
+    pub force_correctness_checks: bool,
+    #[options(
+        help = "which batch exponentiation version to use",
+        default = "auto",
+        parse(try_from_str = "batch_exp_mode_from_str")
+    )]
+    pub batch_exp_mode: BatchExpMode,
+    #[options(
+        help = "which subgroup check version to use",
+        default = "auto",
+        parse(try_from_str = "subgroup_check_mode_from_str")
+    )]
+    pub subgroup_check_mode: SubgroupCheckMode,
+}
+
+// The supported commands
+#[derive(Debug, Options, Clone)]
+pub enum Command {
+    // this creates a new challenge
+    #[options(help = "creates a new challenge for the ceremony")]
+    New(NewOpts),
+    #[options(help = "contribute to ceremony by producing a response to a challenge")]
+    Contribute(ContributeOpts),
+    #[options(help = "verify the contributions so far and generate a new challenge, for a single chunk")]
+    Verify(VerifyOpts),
+    #[options(help = "combine the contributions and verify the final parameters")]
+    Combine(CombineOpts),
+}
+
+// Options for the Contribute command
+#[derive(Debug, Options, Clone)]
+pub struct NewOpts {
+    help: bool,
+    #[options(help = "the challenge file name to be created", default = "challenge")]
+    pub challenge_fname: String,
+    #[options(help = "the new challenge file hash", default = "challenge.verified.hash")]
+    pub challenge_hash_fname: String,
+    #[options(help = "phase 1 file name", default = "phase1")]
+    pub phase1_fname: String,
+    #[options(help = "phase 1 powers")]
+    pub phase1_powers: usize,
+    #[options(help = "number of validators")]
+    pub num_validators: usize,
+    #[options(help = "number of epochs")]
+    pub num_epochs: usize,
+}
+
+// Options for the Contribute command
+#[derive(Debug, Options, Clone)]
+pub struct ContributeOpts {
+    help: bool,
+    #[options(help = "the provided challenge file", default = "challenge")]
+    pub challenge_fname: String,
+    #[options(help = "the provided challenge file hash", default = "challenge.hash")]
+    pub challenge_hash_fname: String,
+    #[options(help = "the response file which will be generated")]
+    pub response_fname: String,
+    #[options(help = "the response file which will be generated hash", default = "response.hash")]
+    pub response_hash_fname: String,
+    #[options(
+        help = "the beacon hash to be used if running a beacon contribution",
+        default = "0000000000000000000a558a61ddc8ee4e488d647a747fe4dcc362fe2026c620"
+    )]
+    pub beacon_hash: String,
+}
+
+#[derive(Debug, Options, Clone)]
+pub struct VerifyOpts {
+    help: bool,
+    #[options(help = "the provided challenge file", default = "challenge")]
+    pub challenge_fname: String,
+    #[options(help = "the provided challenge hash", default = "challenge.verified.hash")]
+    pub challenge_hash_fname: String,
+    #[options(help = "the provided response file which will be verified", default = "response")]
+    pub response_fname: String,
+    #[options(help = "the response file hash", default = "response.verified.hash")]
+    pub response_hash_fname: String,
+}
+
+#[derive(Debug, Options, Clone)]
+pub struct CombineOpts {
+    help: bool,
+    #[options(help = "the provided query initial file", default = "challenge")]
+    pub initial_query_fname: String,
+    #[options(help = "the provided full initial file", default = "challenge")]
+    pub initial_full_fname: String,
+    #[options(help = "the response files which will be combined", default = "response_list")]
+    pub response_list_fname: String,
+    #[options(help = "the combined response file", default = "combined")]
+    pub combined_fname: String,
+}
diff --git a/phase2-cli/src/new_challenge.rs b/phase2-cli/src/new_challenge.rs
new file mode 100644
index 0000000..11b3cec
--- /dev/null
+++ b/phase2-cli/src/new_challenge.rs
@@ -0,0 +1,104 @@
+use phase2::parameters::MPCParameters;
+use setup_utils::{calculate_hash, print_hash, CheckForCorrectness, UseCompression};
+
+use algebra::{bw6_761::Fr, CanonicalSerialize, BW6_761};
+use r1cs_core::ConstraintSynthesizer;
+use r1cs_core::{ConstraintSystem, SynthesisMode};
+
+use epoch_snark::ValidatorSetUpdate;
+use memmap::*;
+use std::{fs::OpenOptions, io::Write};
+use tracing::info;
+
+const COMPRESS_NEW_CHALLENGE: UseCompression = UseCompression::No;
+
+pub fn new_challenge(
+    challenge_filename: &str,
+    challenge_hash_filename: &str,
+    chunk_size: usize,
+    phase1_filename: &str,
+    phase1_powers: usize,
+    num_validators: usize,
+    num_epochs: usize,
+) {
+    info!("Generating phase 2");
+
+    let reader = OpenOptions::new()
+        .read(true)
+        .write(true)
+        .open(&phase1_filename)
+        .expect("unable open phase 1 file in this directory");
+    let mut phase1_readable_map = unsafe {
+        MmapOptions::new()
+            .map_mut(&reader)
+            .expect("unable to create a memory map for input")
+    };
+
+    let c = ValidatorSetUpdate::empty(num_validators, num_epochs, 0, None);
+    let counter = ConstraintSystem::<Fr>::new_ref();
+    counter.set_mode(SynthesisMode::Setup);
+    c.clone().generate_constraints(counter.clone()).unwrap();
+    let phase2_size = std::cmp::max(
+        counter.num_constraints(),
+        counter.num_witness_variables() + counter.num_instance_variables(),
+    )
+    .next_power_of_two();
+
+    let (full_mpc_parameters, query_parameters, all_mpc_parameters) =
+        MPCParameters::<BW6_761>::new_from_buffer_chunked(
+            c,
+            &mut phase1_readable_map,
+            UseCompression::No,
+            CheckForCorrectness::No,
+            1 << phase1_powers,
+            phase2_size,
+            chunk_size,
+        )
+        .unwrap();
+
+    let mut serialized_mpc_parameters = vec![];
+    full_mpc_parameters
+        .write(&mut serialized_mpc_parameters, COMPRESS_NEW_CHALLENGE)
+        .unwrap();
+
+    let mut serialized_query_parameters = vec![];
+    match COMPRESS_NEW_CHALLENGE {
+        UseCompression::No => query_parameters.serialize_uncompressed(&mut serialized_query_parameters),
+        UseCompression::Yes => query_parameters.serialize(&mut serialized_query_parameters),
+    }
+    .unwrap();
+
+    let contribution_hash = {
+        std::fs::File::create(format!("{}.full", challenge_filename))
+            .expect("unable to open new challenge hash file")
+            .write_all(&serialized_mpc_parameters)
+            .expect("unable to write serialized mpc parameters");
+        // Get the hash of the contribution, so the user can compare later
+        calculate_hash(&serialized_mpc_parameters)
+    };
+
+    std::fs::File::create(format!("{}.query", challenge_filename))
+        .expect("unable to open new challenge hash file")
+        .write_all(&serialized_query_parameters)
+        .expect("unable to write serialized mpc parameters");
+
+    for (i, chunk) in all_mpc_parameters.iter().enumerate() {
+        let mut serialized_chunk = vec![];
+        chunk
+            .write(&mut serialized_chunk, COMPRESS_NEW_CHALLENGE)
+            .expect("unable to write chunk");
+        std::fs::File::create(format!("{}.{}", challenge_filename, i))
+            .expect("unable to open new challenge hash file")
+            .write_all(&serialized_chunk)
+            .expect("unable to write serialized mpc parameters");
+    }
+
+    std::fs::File::create(challenge_hash_filename)
+        .expect("unable to open new challenge hash file")
+        .write_all(contribution_hash.as_slice())
+        .expect("unable to write new challenge hash");
+
+    info!("Empty contribution is formed with a hash:");
+    print_hash(&contribution_hash);
+    info!("Wrote a fresh accumulator to challenge file");
+}
diff --git a/phase2-cli/src/verify.rs b/phase2-cli/src/verify.rs
new file mode 100644
index 0000000..b4bd35d
--- /dev/null
+++ b/phase2-cli/src/verify.rs
@@ -0,0 +1,69 @@
+use phase2::parameters::MPCParameters;
+use setup_utils::{calculate_hash, print_hash, CheckForCorrectness, SubgroupCheckMode, UseCompression};
+
+use algebra::BW6_761;
+
+use std::io::Write;
+use tracing::info;
+
+const PREVIOUS_CHALLENGE_IS_COMPRESSED: UseCompression = UseCompression::No;
+const CONTRIBUTION_IS_COMPRESSED: UseCompression = UseCompression::No;
+
+pub fn verify(
+    challenge_filename: &str,
+    challenge_hash_filename: &str,
+    check_input_correctness: CheckForCorrectness,
+    response_filename: &str,
+    response_hash_filename: &str,
+    check_output_correctness: CheckForCorrectness,
+    subgroup_check_mode: SubgroupCheckMode,
+) {
+    info!("Verifying phase 2");
+
+    let challenge_contents = std::fs::read(challenge_filename).expect("should have read challenge");
+    let challenge_hash = calculate_hash(&challenge_contents);
+    std::fs::File::create(challenge_hash_filename)
+        .expect("unable to open current accumulator hash file")
+        .write_all(&challenge_hash)
+        .expect("unable to write current accumulator hash");
+
+    info!("`challenge` file contains decompressed points and has a hash:");
+    print_hash(&challenge_hash);
+
+    let parameters_before = MPCParameters::<BW6_761>::read_fast(
+        challenge_contents.as_slice(),
+        PREVIOUS_CHALLENGE_IS_COMPRESSED,
+        check_input_correctness,
+        true,
+        subgroup_check_mode,
+    )
+    .expect("should have read parameters");
+
+    let response_contents = std::fs::read(response_filename).expect("should have read response");
+    let response_hash = calculate_hash(&response_contents);
+    std::fs::File::create(response_hash_filename)
+        .expect("unable to open current accumulator hash file")
+        .write_all(&response_hash)
+        .expect("unable to write current accumulator hash");
+
+    info!("`response` file contains decompressed points and has a hash:");
+    print_hash(&response_hash);
+
+    let parameters_after = MPCParameters::<BW6_761>::read_fast(
+        response_contents.as_slice(),
+        CONTRIBUTION_IS_COMPRESSED,
+        check_output_correctness,
+        true,
+        subgroup_check_mode,
+    )
+    .expect("should have read parameters");
+
+    parameters_before
+        .verify(&parameters_after)
+        .expect("should have successfully verified");
+    info!(
+        "Done!\n\n\
+              The BLAKE2b hash of response file is:\n"
+    );
+    print_hash(&response_hash);
+}
diff --git a/phase2/Cargo.toml b/phase2/Cargo.toml
index 560121a..8cdf6d5 100644
--- a/phase2/Cargo.toml
+++ b/phase2/Cargo.toml
@@ -19,9 +19,9 @@ required-features = ["phase2/testing"]
 [dependencies]
 setup-utils = { path = "../setup-utils", default-features = false }
 
-zexe_algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra", features = ["bls12_377", "bls12_381", "bw6_761"] }
-zexe_groth16 = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "groth16", features = [] }
-zexe_r1cs_core = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "r1cs-core" }
+algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra", features = ["bls12_377", "bls12_381", "bw6_761"] }
+groth16 = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "groth16", features = [] }
+r1cs_core = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "r1cs-core" }
 
 byteorder = { version = "1.3.4" }
 cfg-if = { version = "0.1.10" }
@@ -46,7 +46,7 @@ phase1 = { path = "../phase1", features = ["testing"] }
 phase2 = { path = "./", features = ["testing"] }
 wasm-bindgen-test = { version = "0.3.15" }
 
-zexe_r1cs_std = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "r1cs-std" }
+r1cs_std = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "r1cs-std" }
 
 rusty-hook = { version = "0.11.2" }
 tracing-subscriber = { version = "0.2.3" }
@@ -54,7 +54,7 @@ tracing-subscriber = { version = "0.2.3" }
 [features]
 default = []
 testing = ["parallel"]
-parallel = ["rayon", "setup-utils/parallel", "zexe_algebra/parallel", "zexe_groth16/parallel"]
+parallel = ["rayon", "setup-utils/parallel", "algebra/parallel", "groth16/parallel"]
 
 cli = ["setup-utils/cli"]
 wasm = ["console_error_panic_hook", "itertools", "web-sys", "setup-utils/wasm"]
diff --git a/phase2/src/chunked_groth16.rs b/phase2/src/chunked_groth16.rs
index fce477c..9a3efce 100644
--- a/phase2/src/chunked_groth16.rs
+++ b/phase2/src/chunked_groth16.rs
@@ -7,13 +7,16 @@ use crate::{
     keypair::{Keypair, PublicKey},
     parameters::*,
 };
-use setup_utils::{batch_mul, check_same_ratio, merge_pairs, InvariantKind, Phase2Error, Result};
+use setup_utils::{
+    batch_mul, check_same_ratio, deserialize, merge_pairs, serialize, BatchExpMode, CheckForCorrectness, InvariantKind,
+    Phase2Error, Result, UseCompression,
+};
 
-use zexe_algebra::{
+use algebra::{
     AffineCurve, CanonicalDeserialize, CanonicalSerialize, ConstantSerializedSize, Field, PairingEngine,
     ProjectiveCurve,
 };
-use zexe_groth16::VerifyingKey;
+use groth16::VerifyingKey;
 
 use byteorder::{BigEndian, WriteBytesExt};
 use rand::Rng;
@@ -27,7 +30,13 @@ use tracing::{debug, info, info_span, trace};
 /// has been correctly calculated from `before`. Large vectors will be read in
 /// `batch_size` batches
 #[allow(clippy::cognitive_complexity)]
-pub fn verify<E: PairingEngine>(before: &mut [u8], after: &mut [u8], batch_size: usize) -> Result<Vec<[u8; 64]>> {
+pub fn verify<E: PairingEngine>(
+    before: &mut [u8],
+    after: &mut [u8],
+    batch_size: usize,
+    compressed: UseCompression,
+    check_correctness: CheckForCorrectness,
+) -> Result<Vec<[u8; 64]>> {
     let span = info_span!("phase2-verify");
     let _enter = span.enter();
     info!("starting...");
@@ -35,14 +44,14 @@ pub fn verify<E: PairingEngine>(before: &mut [u8], after: &mut [u8], batch_size:
     let mut before = std::io::Cursor::new(before);
     let mut after = std::io::Cursor::new(after);
 
-    let vk_before = VerifyingKey::<E>::deserialize(&mut before)?;
-    let beta_g1_before = E::G1Affine::deserialize(&mut before)?;
+    let vk_before = deserialize::<VerifyingKey<E>, _>(&mut before, compressed, check_correctness)?;
+    let beta_g1_before = deserialize::<E::G1Affine, _>(&mut before, compressed, check_correctness)?;
     // we don't need the previous delta_g1 so we can skip it
     before.seek(SeekFrom::Current(E::G1Affine::SERIALIZED_SIZE as i64))?;
 
-    let vk_after = VerifyingKey::<E>::deserialize(&mut after)?;
-    let beta_g1_after = E::G1Affine::deserialize(&mut after)?;
-    let delta_g1_after = E::G1Affine::deserialize(&mut after)?;
+    let vk_after = deserialize::<VerifyingKey<E>, _>(&mut after, compressed, check_correctness)?;
+    let beta_g1_after = deserialize::<E::G1Affine, _>(&mut after, compressed, check_correctness)?;
+    let delta_g1_after = deserialize::<E::G1Affine, _>(&mut after, compressed, check_correctness)?;
 
     // VK parameters remain unchanged, except for Delta G2
     // which we check at the end of the function against the new contribution's
@@ -91,6 +100,8 @@ pub fn verify<E: PairingEngine>(before: &mut [u8], after: &mut [u8], batch_size:
                 after_alpha_g1,
                 batch_size,
                 &InvariantKind::AlphaG1Query,
+                compressed,
+                check_correctness,
             )
         }));
         threads.push(s.spawn(|_| {
@@ -102,6 +113,8 @@ pub fn verify<E: PairingEngine>(before: &mut [u8], after: &mut [u8], batch_size:
                 after_beta_g1,
                 batch_size,
                 &InvariantKind::BetaG1Query,
+                compressed,
+                check_correctness,
             )
         }));
         threads.push(s.spawn(|_| {
@@ -113,6 +126,8 @@ pub fn verify<E: PairingEngine>(before: &mut [u8], after: &mut [u8], batch_size:
                 after_beta_g2,
                 batch_size,
                 &InvariantKind::BetaG2Query,
+                compressed,
+                check_correctness,
             )
         }));
 
@@ -127,6 +142,8 @@ pub fn verify<E: PairingEngine>(before: &mut [u8], after: &mut [u8], batch_size:
                 after_h,
                 vk_after.delta_g2,
                 batch_size,
+                compressed,
+                check_correctness,
                 "H_query ratio check failed",
             )
         }));
@@ -140,6 +157,8 @@ pub fn verify<E: PairingEngine>(before: &mut [u8], after: &mut [u8], batch_size:
                 after_l,
                 vk_after.delta_g2,
                 batch_size,
+                compressed,
+                check_correctness,
                 "L_query ratio check failed",
             )
         }));
@@ -206,7 +225,14 @@ pub fn verify<E: PairingEngine>(before: &mut [u8], after: &mut [u8], batch_size:
 /// followed by the contributions array and the contributions hash), this will modify the
 /// Delta_g1, the VK's Delta_g2 and will update the H and L queries in place while leaving
 /// everything else unchanged
-pub fn contribute<E: PairingEngine, R: Rng>(buffer: &mut [u8], rng: &mut R, batch_size: usize) -> Result<[u8; 64]> {
+pub fn contribute<E: PairingEngine, R: Rng>(
+    buffer: &mut [u8],
+    rng: &mut R,
+    batch_size: usize,
+    compressed: UseCompression,
+    check_correctness: CheckForCorrectness,
+    batch_exp_mode: BatchExpMode,
+) -> Result<[u8; 64]> {
     let span = info_span!("phase2-contribute");
     let _enter = span.enter();
 
@@ -214,11 +240,11 @@ pub fn contribute<E: PairingEngine, R: Rng>(buffer: &mut [u8], rng: &mut R, batc
 
     let mut buffer = std::io::Cursor::new(buffer);
     // The VK is small so we read it directly from the start
-    let mut vk = VerifyingKey::<E>::deserialize(&mut buffer)?;
+    let mut vk = deserialize::<VerifyingKey<E>, _>(&mut buffer, compressed, check_correctness)?;
     // leave beta_g1 unchanged
     buffer.seek(SeekFrom::Current(E::G1Affine::SERIALIZED_SIZE as i64))?;
     // read delta_g1
-    let mut delta_g1 = E::G1Affine::deserialize(&mut buffer)?;
+    let mut delta_g1 = deserialize::<E::G1Affine, _>(&mut buffer, compressed, check_correctness)?;
 
     // Skip the vector elements for now so that we can read the contributions
     skip_vec::<E::G1Affine, _>(&mut buffer)?; // Alpha G1
@@ -280,7 +306,15 @@ pub fn contribute<E: PairingEngine, R: Rng>(buffer: &mut [u8], rng: &mut R, batc
             let _enter1 = span.enter();
             let span = info_span!("h_query");
             let _enter = span.enter();
-            chunked_mul_queries::<E::G1Affine>(h, h_query_len, &delta_inv, batch_size)
+            chunked_mul_queries::<E::G1Affine>(
+                h,
+                h_query_len,
+                &delta_inv,
+                batch_size,
+                compressed,
+                check_correctness,
+                batch_exp_mode,
+            )
         }));
 
         threads.push(s.spawn(|_| {
@@ -294,6 +328,9 @@ pub fn contribute<E: PairingEngine, R: Rng>(buffer: &mut [u8], rng: &mut R, batc
                 l_query_len,
                 &delta_inv,
                 batch_size,
+                compressed,
+                check_correctness,
+                batch_exp_mode,
             )
         }));
 
@@ -342,6 +379,9 @@ fn chunked_mul_queries<C: AffineCurve>(
     query_len: usize,
     element: &C::ScalarField,
     batch_size: usize,
+    compressed: UseCompression,
+    check_correctness: CheckForCorrectness,
+    batch_exp_mode: BatchExpMode,
 ) -> Result<()> {
     let span = info_span!("multiply_query");
     let _enter = span.enter();
@@ -355,7 +395,14 @@ fn chunked_mul_queries<C: AffineCurve>(
         let span = info_span!("iter", i);
         let _enter = span.enter();
 
-        mul_query::<C, _>(&mut buffer, element, batch_size)?;
+        mul_query::<C, _>(
+            &mut buffer,
+            element,
+            batch_size,
+            compressed,
+            check_correctness,
+            batch_exp_mode,
+        )?;
 
         trace!("ok");
     }
@@ -364,7 +411,14 @@ fn chunked_mul_queries<C: AffineCurve>(
         let span = info_span!("iter", i = iters);
         let _enter = span.enter();
 
-        mul_query::<C, _>(&mut buffer, element, leftovers)?;
+        mul_query::<C, _>(
+            &mut buffer,
+            element,
+            leftovers,
+            compressed,
+            check_correctness,
+            batch_exp_mode,
+        )?;
 
         trace!("ok");
     }
@@ -379,18 +433,21 @@ fn mul_query<C: AffineCurve, B: Read + Write + Seek>(
     mut buffer: B,
     element: &C::ScalarField,
     num_els: usize,
+    compressed: UseCompression,
+    check_correctness: CheckForCorrectness,
+    batch_exp_mode: BatchExpMode,
 ) -> Result<()> {
     let mut query = (0..num_els)
-        .map(|_| C::deserialize(&mut buffer))
+        .map(|_| deserialize::<C, _>(&mut buffer, compressed, check_correctness))
         .collect::<std::result::Result<Vec<_>, _>>()?; // why can't we use the aliased error type here?
 
-    batch_mul(&mut query, element)?;
+    batch_mul(&mut query, element, batch_exp_mode)?;
 
     // seek back to update the elements
     buffer.seek(SeekFrom::Current(((num_els * C::SERIALIZED_SIZE) as i64).neg()))?;
     query
         .iter()
-        .map(|el| el.serialize(&mut buffer))
+        .map(|el| serialize(el, &mut buffer, compressed))
         .collect::<std::result::Result<Vec<_>, _>>()?;
 
     Ok(())
@@ -403,6 +460,8 @@ fn chunked_ensure_unchanged_vec<C: AffineCurve>(
     after: &mut [u8],
     batch_size: usize,
     kind: &InvariantKind,
+    compressed: UseCompression,
+    check_correctness: CheckForCorrectness,
 ) -> Result<()> {
     let span = info_span!("unchanged_vec");
     let _enter = span.enter();
@@ -421,7 +480,8 @@ fn chunked_ensure_unchanged_vec<C: AffineCurve>(
         let span1 = info_span!("iter", i);
         let _enter = span1.enter();
 
-        let (els_before, els_after) = read_batch::<C, _>(&mut before, &mut after, batch_size)?;
+        let (els_before, els_after) =
+            read_batch::<C, _>(&mut before, &mut after, batch_size, compressed, check_correctness)?;
         ensure_unchanged_vec(&els_before, &els_after, kind)?;
 
         trace!("ok");
@@ -432,7 +492,8 @@ fn chunked_ensure_unchanged_vec<C: AffineCurve>(
         let span1 = info_span!("iter", i = iters);
         let _enter = span1.enter();
 
-        let (els_before, els_after) = read_batch::<C, _>(&mut before, &mut after, leftovers)?;
+        let (els_before, els_after) =
+            read_batch::<C, _>(&mut before, &mut after, leftovers, compressed, check_correctness)?;
         ensure_unchanged_vec(&els_before, &els_after, kind)?;
 
         trace!("ok");
@@ -450,6 +511,8 @@ fn chunked_check_ratio<E: PairingEngine>(
     after: &mut [u8],
     after_delta_g2: E::G2Affine,
     batch_size: usize,
+    compressed: UseCompression,
+    check_correctness: CheckForCorrectness,
     err: &'static str,
 ) -> Result<()> {
     let span = info_span!("check_ratio");
@@ -469,13 +532,15 @@ fn chunked_check_ratio<E: PairingEngine>(
     let iters = len_before / batch_size;
     let leftovers = len_before % batch_size;
     for _ in 0..iters {
-        let (els_before, els_after) = read_batch::<E::G1Affine, _>(&mut before, &mut after, batch_size)?;
+        let (els_before, els_after) =
+            read_batch::<E::G1Affine, _>(&mut before, &mut after, batch_size, compressed, check_correctness)?;
         let pairs = merge_pairs(&els_before, &els_after);
         check_same_ratio::<E>(&pairs, &(after_delta_g2, before_delta_g2), err)?;
     }
     // in case the batch size did not evenly divide the number of queries
     if leftovers > 0 {
-        let (els_before, els_after) = read_batch::<E::G1Affine, _>(&mut before, &mut after, leftovers)?;
+        let (els_before, els_after) =
+            read_batch::<E::G1Affine, _>(&mut before, &mut after, leftovers, compressed, check_correctness)?;
         let pairs = merge_pairs(&els_before, &els_after);
         check_same_ratio::<E>(&pairs, &(after_delta_g2, before_delta_g2), err)?;
     }
@@ -489,12 +554,14 @@ fn read_batch<C: AffineCurve, B: Read + Write + Seek>(
     mut before: B,
     mut after: B,
     batch_size: usize,
+    compressed: UseCompression,
+    check_correctness: CheckForCorrectness,
 ) -> Result<(Vec<C>, Vec<C>)> {
     let els_before = (0..batch_size)
-        .map(|_| C::deserialize(&mut before))
+        .map(|_| deserialize::<C, _>(&mut before, compressed, check_correctness))
         .collect::<std::result::Result<Vec<_>, _>>()?;
     let els_after = (0..batch_size)
-        .map(|_| C::deserialize(&mut after))
+        .map(|_| deserialize::<C, _>(&mut after, compressed, check_correctness))
         .collect::<std::result::Result<Vec<_>, _>>()?;
     Ok((els_before, els_after))
 }
diff --git a/phase2/src/helpers/testing.rs b/phase2/src/helpers/testing.rs
index caaec09..975945c 100644
--- a/phase2/src/helpers/testing.rs
+++ b/phase2/src/helpers/testing.rs
@@ -1,5 +1,5 @@
-use zexe_algebra::{Field, PairingEngine};
-use zexe_r1cs_core::{lc, ConstraintSynthesizer, ConstraintSystemRef, SynthesisError};
+use algebra::{Field, PairingEngine};
+use r1cs_core::{lc, ConstraintSynthesizer, ConstraintSystemRef, SynthesisError};
 
 // circuit proving knowledge of a square root
 // when generating the Setup, the element inside is None
@@ -22,14 +22,6 @@ impl<E: PairingEngine> ConstraintSynthesizer<E::Fr> for TestCircuit<E> {
             cs.enforce_constraint(lc!() + x, lc!() + x, lc!() + out)?;
         }
 
-        // add some dummy constraints to make the circuit a bit bigger
-        // we do this so that we can write a failing test for our MPC
-        // where the params are smaller than the circuit size
-        // (7 in this case, since we allocated 3 constraints, plus 4 below)
-        for _ in 0..4 {
-            cs.new_witness_variable(|| self.0.ok_or(SynthesisError::AssignmentMissing))
-                .unwrap();
-        }
         Ok(())
     }
 }
@@ -37,8 +29,8 @@ impl<E: PairingEngine> ConstraintSynthesizer<E::Fr> for TestCircuit<E> {
 #[cfg(test)]
 mod tests {
     use super::*;
-    use zexe_algebra::Bls12_377;
-    use zexe_groth16::{create_random_proof, generate_random_parameters, prepare_verifying_key, verify_proof};
+    use algebra::Bls12_377;
+    use groth16::{create_random_proof, generate_random_parameters, prepare_verifying_key, verify_proof};
 
     // no need to run these tests, they're just added as a guideline for how to
     // consume the circuit
diff --git a/phase2/src/keypair.rs b/phase2/src/keypair.rs
index b97d2cf..26cb329 100644
--- a/phase2/src/keypair.rs
+++ b/phase2/src/keypair.rs
@@ -4,9 +4,7 @@
 //! Dispose of the private key ASAP once it's been used.
 use setup_utils::{hash_to_g2, CheckForCorrectness, Deserializer, HashWriter, Result, Serializer, UseCompression};
 
-use zexe_algebra::{
-    AffineCurve, CanonicalSerialize, ConstantSerializedSize, PairingEngine, ProjectiveCurve, UniformRand,
-};
+use algebra::{AffineCurve, CanonicalSerialize, ConstantSerializedSize, PairingEngine, ProjectiveCurve, UniformRand};
 
 use byteorder::{BigEndian, ReadBytesExt, WriteBytesExt};
 use rand::Rng;
@@ -204,8 +202,8 @@ impl<E: PairingEngine> PartialEq for PublicKey<E> {
 #[cfg(test)]
 mod tests {
     use super::*;
+    use algebra::Bls12_377;
     use rand::thread_rng;
-    use zexe_algebra::Bls12_377;
 
     #[test]
     fn serialization() {
diff --git a/phase2/src/lib.rs b/phase2/src/lib.rs
index d9b5d65..be84b08 100644
--- a/phase2/src/lib.rs
+++ b/phase2/src/lib.rs
@@ -15,7 +15,7 @@ cfg_if! {
         use wasm_bindgen::prelude::*;
         use itertools::Itertools;
         use parameters::MPCParameters;
-        use zexe_algebra::{Bls12_377, BW6_761, PairingEngine};
+        use algebra::{Bls12_377, BW6_761, PairingEngine};
         use setup_utils::{ get_rng, user_system_randomness };
 
         macro_rules! log {
@@ -28,8 +28,20 @@ cfg_if! {
 
             log!("Initializing phase2");
             let res = match is_inner {
-                true => contribute_challenge(&mut MPCParameters::<Bls12_377>::read(&*params).unwrap()),
-                false => contribute_challenge(&mut MPCParameters::<BW6_761>::read(&*params).unwrap()),
+                true => contribute_challenge(&mut MPCParameters::<Bls12_377>::read(
+                    &*params,
+                    UseCompression::Yes,
+                    CheckForCorrectness::Full,
+                    false,
+                    SubgroupCheckMode::Auto,
+                ).unwrap()),
+                false => contribute_challenge(&mut MPCParameters::<BW6_761>::read(
+                    &*params,
+                    UseCompression::Yes,
+                    CheckForCorrectness::Full,
+                    false,
+                    SubgroupCheckMode::Auto,
+                ).unwrap()),
             };
 
             Ok(res)
diff --git a/phase2/src/parameters.rs b/phase2/src/parameters.rs
index a048fb0..068ee45 100644
--- a/phase2/src/parameters.rs
+++ b/phase2/src/parameters.rs
@@ -3,9 +3,9 @@ use cfg_if::cfg_if;
 cfg_if! {
     if #[cfg(not(feature = "wasm"))] {
         use super::polynomial::eval;
-        use zexe_algebra::{ Zero };
-        use zexe_groth16::{VerifyingKey};
-        use zexe_r1cs_core::SynthesisError;
+        use algebra::{ Zero };
+        use groth16::{Parameters, VerifyingKey};
+        use r1cs_core::SynthesisError;
     }
 }
 
@@ -13,9 +13,10 @@ use super::keypair::{hash_cs_pubkeys, Keypair, PublicKey};
 
 use setup_utils::*;
 
-use zexe_algebra::{AffineCurve, CanonicalDeserialize, CanonicalSerialize, Field, PairingEngine, ProjectiveCurve};
-use zexe_groth16::Parameters;
-use zexe_r1cs_core::{lc, ConstraintSynthesizer, ConstraintSystem, ConstraintSystemRef, SynthesisMode, Variable};
+use algebra::{
+    AffineCurve, CanonicalDeserialize, CanonicalSerialize, Field, PairingEngine, ProjectiveCurve, SerializationError,
+};
+use r1cs_core::{lc, ConstraintSynthesizer, ConstraintSystem, ConstraintSystemRef, SynthesisMode, Variable};
 
 use rand::Rng;
 use std::{
@@ -23,6 +24,24 @@ use std::{
     io::{self, Read, Write},
 };
 
+trait SerializeWithCompression<W: Write> {
+    fn serialize_compressed(writer: &W);
+
+    fn serialize_uncompressed(writer: &W);
+}
+
+trait DeserializeWithCompression<R: Read> {
+    fn deserialize_compressed(reader: &R) -> Self;
+
+    fn deserialize_uncompressed(reader: &R) -> Self;
+}
+
+#[derive(Clone, PartialEq, Eq, Debug, Copy)]
+pub enum Phase2ContributionMode {
+    Full,
+    Chunked,
+}
+
 /// MPC parameters are just like Zexe's `Parameters` except, when serialized,
 /// they contain a transcript of contributions at the end, which can be verified.
 #[derive(Clone)]
@@ -76,7 +95,42 @@ impl<E: PairingEngine> MPCParameters<E> {
         Self::new(assembly, params)
     }
 
-    /// Create new Groth16 parameters (compatible with Zexe and snarkOS) for a
+    #[cfg(not(feature = "wasm"))]
+    pub fn new_from_buffer_chunked<C>(
+        circuit: C,
+        transcript: &mut [u8],
+        compressed: UseCompression,
+        check_input_for_correctness: CheckForCorrectness,
+        phase1_size: usize,
+        phase2_size: usize,
+        chunk_size: usize,
+    ) -> Result<(MPCParameters<E>, Parameters<E>, Vec<MPCParameters<E>>)>
+    where
+        C: ConstraintSynthesizer<E::Fr>,
+    {
+        let assembly = circuit_to_qap::<E, _>(circuit)?;
+        let params = Groth16Params::<E>::read(
+            transcript,
+            compressed,
+            check_input_for_correctness,
+            phase1_size,
+            phase2_size,
+        )?;
+        Self::new_chunked(assembly, params, chunk_size)
+    }
+
+    #[cfg(not(feature = "wasm"))]
+    fn process_matrix(xt: &[Vec<(E::Fr, usize)>], cs: ConstraintSystemRef<E::Fr>) -> Vec<Vec<(E::Fr, usize)>> {
+        let mut xt_processed = vec![vec![]; cs.num_instance_variables() + cs.num_witness_variables()];
+        for (constraint_num, vars) in xt.iter().enumerate() {
+            for (coeff, var_index) in vars {
+                xt_processed[*var_index].push((*coeff, constraint_num));
+            }
+        }
+        xt_processed
+    }
+
+    /// Create new Groth16 parameters (compatible with Zexe) for a
     /// given QAP which has been produced from a circuit. The resulting parameters
     /// are unsafe to use until there are contributions (see `contribute()`).
     #[cfg(not(feature = "wasm"))]
@@ -86,6 +140,11 @@ impl<E: PairingEngine> MPCParameters<E> {
             let matrices = cs.to_matrices().unwrap();
             (matrices.a, matrices.b, matrices.c)
         };
+
+        let at = Self::process_matrix(&at, cs.clone());
+        let bt = Self::process_matrix(&bt, cs.clone());
+        let ct = Self::process_matrix(&ct, cs.clone());
+
         let (a_g1, b_g1, b_g2, gamma_abc_g1, l) = eval::<E>(
             // Lagrange coeffs for Tau, read in from Phase 1
             &params.coeffs_g1,
@@ -136,6 +195,116 @@ impl<E: PairingEngine> MPCParameters<E> {
         })
     }
 
+    #[cfg(not(feature = "wasm"))]
+    pub fn new_chunked(
+        cs: ConstraintSystemRef<E::Fr>,
+        params: Groth16Params<E>,
+        chunk_size: usize,
+    ) -> Result<(MPCParameters<E>, Parameters<E>, Vec<MPCParameters<E>>)> {
+        // Evaluate the QAP against the coefficients created from phase 1
+        let (at, bt, ct) = {
+            let matrices = cs.to_matrices().unwrap();
+            (matrices.a, matrices.b, matrices.c)
+        };
+
+        let at = Self::process_matrix(&at, cs.clone());
+        let bt = Self::process_matrix(&bt, cs.clone());
+        let ct = Self::process_matrix(&ct, cs.clone());
+
+        let (a_g1, b_g1, b_g2, gamma_abc_g1, l) = eval::<E>(
+            // Lagrange coeffs for Tau, read in from Phase 1
+            &params.coeffs_g1,
+            &params.coeffs_g2,
+            &params.alpha_coeffs_g1,
+            &params.beta_coeffs_g1,
+            // QAP polynomials of the circuit
+            &at,
+            &bt,
+            &ct,
+            // Helper
+            cs.num_instance_variables(),
+        );
+
+        // Reject unconstrained elements, so that
+        // the L query is always fully dense.
+        for e in l.iter() {
+            if e.is_zero() {
+                return Err(SynthesisError::UnconstrainedVariable.into());
+            }
+        }
+
+        let vk = VerifyingKey {
+            alpha_g1: params.alpha_g1,
+            beta_g2: params.beta_g2,
+            // Gamma_g2 is always 1, since we're implementing
+            // BGM17, pg14 https://eprint.iacr.org/2017/1050.pdf
+            gamma_g2: E::G2Affine::prime_subgroup_generator(),
+            delta_g2: E::G2Affine::prime_subgroup_generator(),
+            gamma_abc_g1,
+        };
+        let params = Parameters {
+            vk,
+            beta_g1: params.beta_g1,
+            delta_g1: E::G1Affine::prime_subgroup_generator(),
+            a_query: a_g1,
+            b_g1_query: b_g1,
+            b_g2_query: b_g2,
+            h_query: params.h_g1,
+            l_query: l,
+        };
+
+        let query_parameters = Parameters::<E> {
+            vk: params.vk.clone(),
+            beta_g1: params.beta_g1.clone(),
+            delta_g1: params.delta_g1.clone(),
+            a_query: params.a_query.clone(),
+            b_g1_query: params.b_g1_query.clone(),
+            b_g2_query: params.b_g2_query.clone(),
+            h_query: vec![],
+            l_query: vec![],
+        };
+        let cs_hash = hash_params(&params)?;
+        let full_mpc = MPCParameters {
+            params: params.clone(),
+            cs_hash,
+            contributions: vec![],
+        };
+
+        let mut chunks = vec![];
+        let max_query = std::cmp::max(params.h_query.len(), params.l_query.len());
+        let num_chunks = (max_query + chunk_size - 1) / chunk_size;
+        for i in 0..num_chunks {
+            let chunk_start = i * chunk_size;
+            let chunk_end = (i + 1) * chunk_size;
+            let h_query_for_chunk = if chunk_start < params.h_query.len() {
+                params.h_query[chunk_start..std::cmp::min(chunk_end, params.h_query.len())].to_vec()
+            } else {
+                vec![]
+            };
+            let l_query_for_chunk = if chunk_start < params.l_query.len() {
+                params.l_query[chunk_start..std::cmp::min(chunk_end, params.l_query.len())].to_vec()
+            } else {
+                vec![]
+            };
+            let chunk_params = MPCParameters {
+                params: Parameters::<E> {
+                    vk: params.vk.clone(),
+                    beta_g1: params.beta_g1.clone(),
+                    delta_g1: params.delta_g1.clone(),
+                    a_query: vec![],
+                    b_g1_query: vec![],
+                    b_g2_query: vec![],
+                    h_query: h_query_for_chunk,
+                    l_query: l_query_for_chunk,
+                },
+                cs_hash,
+                contributions: vec![],
+            };
+            chunks.push(chunk_params);
+        }
+        Ok((full_mpc, query_parameters, chunks))
+    }
+
     /// Get the underlying Groth16 `Parameters`
     pub fn get_params(&self) -> &Parameters<E> {
         &self.params
@@ -150,7 +319,7 @@ impl<E: PairingEngine> MPCParameters<E> {
     /// sure their contribution is in the final parameters, by
     /// checking to see if it appears in the output of
     /// `MPCParameters::verify`.
-    pub fn contribute<R: Rng>(&mut self, rng: &mut R) -> Result<[u8; 64]> {
+    pub fn contribute<R: Rng>(&mut self, batch_exp_mode: BatchExpMode, rng: &mut R) -> Result<[u8; 64]> {
         // Generate a keypair
         let Keypair {
             public_key,
@@ -159,8 +328,8 @@ impl<E: PairingEngine> MPCParameters<E> {
 
         // Invert delta and multiply the query's `l` and `h` by it
         let delta_inv = private_key.delta.inverse().expect("nonzero");
-        batch_mul(&mut self.params.l_query, &delta_inv)?;
-        batch_mul(&mut self.params.h_query, &delta_inv)?;
+        batch_mul(&mut self.params.l_query, &delta_inv, batch_exp_mode)?;
+        batch_mul(&mut self.params.h_query, &delta_inv, batch_exp_mode)?;
 
         // Multiply the `delta_g1` and `delta_g2` elements by the private key's delta
         self.params.vk.delta_g2 = self.params.vk.delta_g2.mul(private_key.delta).into_affine();
@@ -257,26 +426,56 @@ impl<E: PairingEngine> MPCParameters<E> {
         )?;
 
         // H and L queries should be updated with delta^-1
-        check_same_ratio::<E>(
-            &merge_pairs(&before.params.h_query, &after.params.h_query),
-            &(after.params.vk.delta_g2, before.params.vk.delta_g2), // reversed for inverse
-            "H_query ratio check failed",
-        )?;
+        if before.params.h_query.len() > 0 {
+            check_same_ratio::<E>(
+                &merge_pairs(&before.params.h_query, &after.params.h_query),
+                &(after.params.vk.delta_g2, before.params.vk.delta_g2), // reversed for inverse
+                "H_query ratio check failed",
+            )?;
+        }
 
-        check_same_ratio::<E>(
-            &merge_pairs(&before.params.l_query, &after.params.l_query),
-            &(after.params.vk.delta_g2, before.params.vk.delta_g2), // reversed for inverse
-            "L_query ratio check failed",
-        )?;
+        if before.params.l_query.len() > 0 {
+            check_same_ratio::<E>(
+                &merge_pairs(&before.params.l_query, &after.params.l_query),
+                &(after.params.vk.delta_g2, before.params.vk.delta_g2), // reversed for inverse
+                "L_query ratio check failed",
+            )?;
+        }
 
         // generate the transcript from the current contributions and the previous cs_hash
         verify_transcript(before.cs_hash, &after.contributions)
     }
 
+    pub fn combine(queries: &Parameters<E>, mpcs: &[MPCParameters<E>]) -> Result<MPCParameters<E>> {
+        let mut combined_mpc = MPCParameters::<E> {
+            params: Parameters::<E> {
+                vk: mpcs[0].params.vk.clone(),
+                beta_g1: mpcs[0].params.beta_g1.clone(),
+                delta_g1: mpcs[0].params.delta_g1.clone(),
+                a_query: queries.a_query.clone(),
+                b_g1_query: queries.b_g1_query.clone(),
+                b_g2_query: queries.b_g2_query.clone(),
+                h_query: vec![],
+                l_query: vec![],
+            },
+            cs_hash: mpcs[0].cs_hash,
+            contributions: mpcs[0].contributions.clone(),
+        };
+        for mpc in mpcs {
+            combined_mpc.params.h_query.extend_from_slice(&mpc.params.h_query);
+            combined_mpc.params.l_query.extend_from_slice(&mpc.params.l_query);
+        }
+
+        Ok(combined_mpc)
+    }
+
     /// Serialize these parameters. The serialized parameters
     /// can be read by Zexe's Groth16 `Parameters`.
-    pub fn write<W: Write>(&self, mut writer: W) -> Result<()> {
-        self.params.serialize(&mut writer)?;
+    pub fn write<W: Write>(&self, mut writer: W, compressed: UseCompression) -> Result<()> {
+        match compressed {
+            UseCompression::No => self.params.serialize_uncompressed(&mut writer),
+            UseCompression::Yes => self.params.serialize(&mut writer),
+        }?;
         writer.write_all(&self.cs_hash)?;
         PublicKey::write_batch(&mut writer, &self.contributions)?;
 
@@ -284,8 +483,41 @@ impl<E: PairingEngine> MPCParameters<E> {
     }
 
     /// Deserialize these parameters.
-    pub fn read<R: Read>(mut reader: R) -> Result<MPCParameters<E>> {
-        let params = Parameters::deserialize(&mut reader)?;
+    pub fn read<R: Read>(
+        mut reader: R,
+        compressed: UseCompression,
+        check_correctness: CheckForCorrectness,
+        check_subgroup_membership: bool,
+        subgroup_check_mode: SubgroupCheckMode,
+    ) -> Result<MPCParameters<E>> {
+        let params = match (compressed, check_correctness) {
+            (UseCompression::No, CheckForCorrectness::Full) => Parameters::deserialize_uncompressed(&mut reader),
+            (UseCompression::Yes, CheckForCorrectness::Full) => Parameters::deserialize(&mut reader),
+            (UseCompression::No, CheckForCorrectness::No) | (UseCompression::No, CheckForCorrectness::OnlyNonZero) => {
+                Parameters::deserialize_uncompressed_unchecked(&mut reader)
+            }
+            (UseCompression::Yes, CheckForCorrectness::No)
+            | (UseCompression::Yes, CheckForCorrectness::OnlyNonZero) => Parameters::deserialize_unchecked(&mut reader),
+            (..) => Err(SerializationError::InvalidData),
+        }?;
+
+        // In the Full mode, this is already checked
+        if check_subgroup_membership && check_correctness != CheckForCorrectness::Full {
+            check_subgroup(&params.a_query, subgroup_check_mode)?;
+            check_subgroup(&params.b_g1_query, subgroup_check_mode)?;
+            check_subgroup(&params.b_g2_query, subgroup_check_mode)?;
+            check_subgroup(&params.h_query, subgroup_check_mode)?;
+            check_subgroup(&params.l_query, subgroup_check_mode)?;
+            check_subgroup(&params.vk.gamma_abc_g1, subgroup_check_mode)?;
+            check_subgroup(
+                &vec![params.beta_g1, params.delta_g1, params.vk.alpha_g1],
+                subgroup_check_mode,
+            )?;
+            check_subgroup(
+                &vec![params.vk.beta_g2, params.vk.delta_g2, params.vk.gamma_g2],
+                subgroup_check_mode,
+            )?;
+        }
 
         let mut cs_hash = [0u8; 64];
         reader.read_exact(&mut cs_hash)?;
@@ -298,6 +530,96 @@ impl<E: PairingEngine> MPCParameters<E> {
             contributions,
         })
     }
+
+    pub fn read_fast<R: Read>(
+        mut reader: R,
+        compressed: UseCompression,
+        check_correctness: CheckForCorrectness,
+        check_subgroup_membership: bool,
+        subgroup_check_mode: SubgroupCheckMode,
+    ) -> Result<MPCParameters<E>> {
+        let params = Self::read_groth16_fast(
+            &mut reader,
+            compressed,
+            check_correctness,
+            check_subgroup_membership,
+            subgroup_check_mode,
+        )?;
+
+        let mut cs_hash = [0u8; 64];
+        reader.read_exact(&mut cs_hash)?;
+
+        let contributions = PublicKey::read_batch(&mut reader)?;
+
+        let mpc_params = MPCParameters::<E> {
+            params,
+            cs_hash,
+            contributions,
+        };
+
+        Ok(mpc_params)
+    }
+
+    pub fn read_groth16_fast<R: Read>(
+        mut reader: R,
+        compressed: UseCompression,
+        check_correctness: CheckForCorrectness,
+        check_subgroup_membership: bool,
+        subgroup_check_mode: SubgroupCheckMode,
+    ) -> Result<Parameters<E>> {
+        // vk
+        let alpha_g1: E::G1Affine = reader.read_element(compressed, check_correctness)?;
+        let beta_g2: E::G2Affine = reader.read_element(compressed, check_correctness)?;
+        let gamma_g2: E::G2Affine = reader.read_element(compressed, check_correctness)?;
+        let delta_g2: E::G2Affine = reader.read_element(compressed, check_correctness)?;
+        let gamma_abc_g1: Vec<E::G1Affine> = read_vec(&mut reader, compressed, check_correctness)?;
+
+        // rest of the parameters
+        let beta_g1: E::G1Affine = reader.read_element(compressed, check_correctness)?;
+        let delta_g1: E::G1Affine = reader.read_element(compressed, check_correctness)?;
+        let a_query: Vec<E::G1Affine> = read_vec(&mut reader, compressed, check_correctness)?;
+        let b_g1_query: Vec<E::G1Affine> = read_vec(&mut reader, compressed, check_correctness)?;
+        let b_g2_query: Vec<E::G2Affine> = read_vec(&mut reader, compressed, check_correctness)?;
+        let h_query: Vec<E::G1Affine> = read_vec(&mut reader, compressed, check_correctness)?;
+        let l_query: Vec<E::G1Affine> = read_vec(&mut reader, compressed, check_correctness)?;
+
+        let params = Parameters::<E> {
+            vk: VerifyingKey::<E> {
+                alpha_g1,
+                beta_g2,
+                gamma_g2,
+                delta_g2,
+                gamma_abc_g1,
+            },
+            beta_g1,
+            delta_g1,
+            a_query,
+            b_g1_query,
+            b_g2_query,
+            h_query,
+            l_query,
+        };
+
+        // In the Full mode, this is already checked
+        if check_subgroup_membership && check_correctness != CheckForCorrectness::Full {
+            check_subgroup(&params.a_query, subgroup_check_mode)?;
+            check_subgroup(&params.b_g1_query, subgroup_check_mode)?;
+            check_subgroup(&params.b_g2_query, subgroup_check_mode)?;
+            check_subgroup(&params.h_query, subgroup_check_mode)?;
+            check_subgroup(&params.l_query, subgroup_check_mode)?;
+            check_subgroup(&params.vk.gamma_abc_g1, subgroup_check_mode)?;
+            check_subgroup(
+                &vec![params.beta_g1, params.delta_g1, params.vk.alpha_g1],
+                subgroup_check_mode,
+            )?;
+            check_subgroup(
+                &vec![params.vk.beta_g2, params.vk.delta_g2, params.vk.gamma_g2],
+                subgroup_check_mode,
+            )?;
+        }
+
+        Ok(params)
+    }
 }
 
 /// This is a cheap helper utility that exists purely
@@ -398,6 +720,7 @@ pub fn circuit_to_qap<Zexe: PairingEngine, C: ConstraintSynthesizer<Zexe::Fr>>(
     for i in 0..cs.num_instance_variables() {
         cs.enforce_constraint(lc!() + Variable::Instance(i), lc!(), lc!())?;
     }
+    cs.inline_all_lcs();
 
     Ok(cs)
 }
@@ -412,7 +735,7 @@ mod tests {
     use phase1::{helpers::testing::setup_verify, Phase1, Phase1Parameters, ProvingSystem};
     use setup_utils::{Groth16Params, UseCompression};
 
-    use zexe_algebra::Bls12_377;
+    use algebra::Bls12_377;
 
     use rand::thread_rng;
     use tracing_subscriber::{filter::EnvFilter, fmt::Subscriber};
@@ -426,10 +749,17 @@ mod tests {
         let mpc = generate_ceremony::<E>();
 
         let mut writer = vec![];
-        mpc.write(&mut writer).unwrap();
+        mpc.write(&mut writer, UseCompression::Yes).unwrap();
         let mut reader = vec![0; writer.len()];
         reader.copy_from_slice(&writer);
-        let deserialized = MPCParameters::<E>::read(&reader[..]).unwrap();
+        let deserialized = MPCParameters::<E>::read(
+            &reader[..],
+            UseCompression::Yes,
+            CheckForCorrectness::Full,
+            false,
+            SubgroupCheckMode::Auto,
+        )
+        .unwrap();
         assert_eq!(deserialized, mpc)
     }
 
@@ -467,19 +797,26 @@ mod tests {
         // original
         let mpc = generate_ceremony::<E>();
         let mut mpc_serialized = vec![];
-        mpc.write(&mut mpc_serialized).unwrap();
+        mpc.write(&mut mpc_serialized, UseCompression::Yes).unwrap();
         let mut mpc_cursor = std::io::Cursor::new(mpc_serialized.clone());
 
         // first contribution
         let mut contribution1 = mpc.clone();
-        contribution1.contribute(rng).unwrap();
+        contribution1.contribute(BatchExpMode::Auto, rng).unwrap();
         let mut c1_serialized = vec![];
-        contribution1.write(&mut c1_serialized).unwrap();
+        contribution1.write(&mut c1_serialized, UseCompression::Yes).unwrap();
         let mut c1_cursor = std::io::Cursor::new(c1_serialized.clone());
 
         // verify it against the previous step
         mpc.verify(&contribution1).unwrap();
-        verify::<E>(&mut mpc_serialized.as_mut(), &mut c1_serialized.as_mut(), 4).unwrap();
+        verify::<E>(
+            &mut mpc_serialized.as_mut(),
+            &mut c1_serialized.as_mut(),
+            4,
+            UseCompression::Yes,
+            CheckForCorrectness::Full,
+        )
+        .unwrap();
         // after each call on the cursors the cursor's position is at the end,
         // so we have to reset it for further testing!
         mpc_cursor.set_position(0);
@@ -488,29 +825,58 @@ mod tests {
         // second contribution via batched method
         let mut c2_buf = c1_serialized.clone();
         c2_buf.resize(c2_buf.len() + PublicKey::<E>::size(), 0); // make the buffer larger by 1 contribution
-        contribute::<E, _>(&mut c2_buf, rng, 4).unwrap();
+        contribute::<E, _>(
+            &mut c2_buf,
+            rng,
+            4,
+            UseCompression::Yes,
+            CheckForCorrectness::Full,
+            BatchExpMode::Auto,
+        )
+        .unwrap();
         let mut c2_cursor = std::io::Cursor::new(c2_buf.clone());
         c2_cursor.set_position(0);
 
         // verify it against the previous step
-        verify::<E>(&mut c1_serialized.as_mut(), &mut c2_buf.as_mut(), 4).unwrap();
+        verify::<E>(
+            &mut c1_serialized.as_mut(),
+            &mut c2_buf.as_mut(),
+            4,
+            UseCompression::Yes,
+            CheckForCorrectness::Full,
+        )
+        .unwrap();
         c1_cursor.set_position(0);
         c2_cursor.set_position(0);
 
         // verify it against the original mpc
-        verify::<E>(&mut mpc_serialized.as_mut(), &mut c2_buf.as_mut(), 4).unwrap();
+        verify::<E>(
+            &mut mpc_serialized.as_mut(),
+            &mut c2_buf.as_mut(),
+            4,
+            UseCompression::Yes,
+            CheckForCorrectness::Full,
+        )
+        .unwrap();
         mpc_cursor.set_position(0);
         c2_cursor.set_position(0);
 
         // the de-serialized versions are also compatible
-        let contribution2 = MPCParameters::<E>::read(&mut c2_cursor).unwrap();
+        let contribution2 = MPCParameters::<E>::read(
+            &mut c2_cursor,
+            UseCompression::Yes,
+            CheckForCorrectness::Full,
+            false,
+            SubgroupCheckMode::Auto,
+        )
+        .unwrap();
         c2_cursor.set_position(0);
         mpc.verify(&contribution2).unwrap();
         contribution1.verify(&contribution2).unwrap();
 
         // third contribution
         let mut contribution3 = contribution2.clone();
-        contribution3.contribute(rng).unwrap();
+        contribution3.contribute(BatchExpMode::Auto, rng).unwrap();
 
         // it's a valid contribution against all previous steps
         mpc.verify(&contribution3).unwrap();
diff --git a/phase2/src/polynomial.rs b/phase2/src/polynomial.rs
index 0b51112..93deddf 100644
--- a/phase2/src/polynomial.rs
+++ b/phase2/src/polynomial.rs
@@ -1,4 +1,4 @@
-use zexe_algebra::{AffineCurve, PairingEngine, ProjectiveCurve, Zero};
+use algebra::{AffineCurve, PairingEngine, ProjectiveCurve, Zero};
 
 use rayon::prelude::*;
 
@@ -93,12 +93,12 @@ fn dot_product<C: AffineCurve>(input: &[(C::ScalarField, usize)], coeffs: &[C])
 #[cfg(test)]
 mod tests {
     use super::*;
-    use phase1::helpers::testing::random_point_vec;
-    use rand::{thread_rng, Rng};
-    use zexe_algebra::{
+    use algebra::{
         bls12_377::{Bls12_377, Fr, G1Affine, G1Projective},
         UniformRand,
     };
+    use phase1::helpers::testing::random_point_vec;
+    use rand::{thread_rng, Rng};
 
     fn gen_input(rng: &mut impl Rng) -> Vec<(Fr, usize)> {
         let scalar = (0..6).map(|_| Fr::rand(rng)).collect::<Vec<_>>();
diff --git a/phase2/tests/mpc.rs b/phase2/tests/mpc.rs
index 93f303e..0d0f2a5 100644
--- a/phase2/tests/mpc.rs
+++ b/phase2/tests/mpc.rs
@@ -1,24 +1,39 @@
+use algebra::{Bls12_377, Bls12_381, PairingEngine, PrimeField, BW6_761};
+use groth16::{create_random_proof, prepare_verifying_key, verify_proof, Parameters};
 use phase1::{
     helpers::testing::{setup_verify, CheckForCorrectness},
     parameters::Phase1Parameters,
     Phase1, ProvingSystem,
 };
-use phase2::{helpers::testing::TestCircuit, parameters::MPCParameters};
+use phase2::{
+    chunked_groth16::verify,
+    helpers::testing::TestCircuit,
+    parameters::{MPCParameters, Phase2ContributionMode},
+};
+use r1cs_core::{ConstraintSynthesizer, ConstraintSystem, SynthesisMode};
 use rand::{thread_rng, Rng};
-use setup_utils::{BatchExpMode, Groth16Params, UseCompression};
-use zexe_algebra::{Bls12_377, Bls12_381, PairingEngine, PrimeField, BW6_761};
-use zexe_groth16::{create_random_proof, prepare_verifying_key, verify_proof, Parameters};
-use zexe_r1cs_core::{ConstraintSynthesizer, ConstraintSystem, SynthesisMode};
+use setup_utils::{derive_rng_from_seed, BatchExpMode, Groth16Params, UseCompression};
 
 fn generate_mpc_parameters<E, C>(c: C, rng: &mut impl Rng) -> MPCParameters<E>
 where
     E: PairingEngine,
     C: Clone + ConstraintSynthesizer<E::Fr>,
 {
-    let powers = 6; // powers of tau
+    // perform the MPC on only the amount of constraints required for the circuit
+    let counter = ConstraintSystem::new_ref();
+    counter.set_mode(SynthesisMode::Setup);
+    c.clone().generate_constraints(counter.clone()).unwrap();
+    let phase2_size = std::cmp::max(
+        counter.num_constraints() + counter.num_instance_variables(),
+        counter.num_witness_variables() + counter.num_instance_variables(),
+    )
+    .next_power_of_two();
+    let powers = (phase2_size as u64).trailing_zeros() as usize;
+
     let batch = 4;
     let params = Phase1Parameters::<E>::new_full(ProvingSystem::Groth16, powers, batch);
     let compressed = UseCompression::Yes;
+
     // make 1 power of tau contribution (assume powers of tau gets calculated properly)
     let (_, output, _, _) = setup_verify(
         compressed,
@@ -31,7 +46,7 @@ where
 
     // prepare only the first 32 powers (for whatever reason)
     let groth_params = Groth16Params::<E>::new(
-        32,
+        1 << powers,
         accumulator.tau_powers_g1,
         accumulator.tau_powers_g2,
         accumulator.alpha_tau_powers_g1,
@@ -39,36 +54,116 @@ where
         accumulator.beta_g2,
     )
     .unwrap();
+
     // write the transcript to a file
     let mut writer = vec![];
     groth_params.write(&mut writer, compressed).unwrap();
 
+    let mut mpc = MPCParameters::<E>::new_from_buffer(
+        c,
+        writer.as_mut(),
+        compressed,
+        CheckForCorrectness::Full,
+        1 << powers,
+        phase2_size,
+    )
+    .unwrap();
+
+    let before = mpc.clone();
+    // it is _not_ safe to use it yet, there must be 1 contribution
+    mpc.contribute(BatchExpMode::Auto, rng).unwrap();
+
+    before.verify(&mpc).unwrap();
+
+    mpc
+}
+
+fn generate_mpc_parameters_chunked<E, C>(c: C) -> MPCParameters<E>
+where
+    E: PairingEngine,
+    C: Clone + ConstraintSynthesizer<E::Fr>,
+{
     // perform the MPC on only the amount of constraints required for the circuit
     let counter = ConstraintSystem::new_ref();
     counter.set_mode(SynthesisMode::Setup);
     c.clone().generate_constraints(counter.clone()).unwrap();
     let phase2_size = std::cmp::max(
-        counter.num_constraints(),
-        counter.num_witness_variables() + counter.num_instance_variables() + 1,
+        counter.num_constraints() + counter.num_instance_variables(),
+        counter.num_witness_variables() + counter.num_instance_variables(),
+    )
+    .next_power_of_two();
+    let powers = (phase2_size as u64).trailing_zeros() as usize;
+
+    let batch = 4;
+    let params = Phase1Parameters::<E>::new_full(ProvingSystem::Groth16, powers, batch);
+    let compressed = UseCompression::Yes;
+
+    // make 1 power of tau contribution (assume powers of tau gets calculated properly)
+    let (_, output, _, _) = setup_verify(
+        compressed,
+        CheckForCorrectness::Full,
+        compressed,
+        BatchExpMode::Auto,
+        &params,
     );
+    let accumulator = Phase1::deserialize(&output, compressed, CheckForCorrectness::Full, &params).unwrap();
 
-    let mut mpc = MPCParameters::<E>::new_from_buffer(
+    // prepare only the first 32 powers (for whatever reason)
+    let groth_params = Groth16Params::<E>::new(
+        1 << powers,
+        accumulator.tau_powers_g1,
+        accumulator.tau_powers_g2,
+        accumulator.alpha_tau_powers_g1,
+        accumulator.beta_tau_powers_g1,
+        accumulator.beta_g2,
+    )
+    .unwrap();
+    // write the transcript to a file
+    let mut writer = vec![];
+    groth_params.write(&mut writer, compressed).unwrap();
+
+    let chunk_size = phase2_size / 3;
+
+    let (full_mpc_before, queries, mut mpcs) = MPCParameters::<E>::new_from_buffer_chunked(
         c,
         writer.as_mut(),
         compressed,
         CheckForCorrectness::Full,
-        32,
+        1 << powers,
         phase2_size,
+        chunk_size,
     )
     .unwrap();
 
-    let before = mpc.clone();
-    // it is _not_ safe to use it yet, there must be 1 contribution
-    mpc.contribute(rng).unwrap();
+    let mut full_mpc_before_serialized = vec![];
+    full_mpc_before
+        .write(&mut full_mpc_before_serialized, UseCompression::Yes)
+        .unwrap();
 
-    before.verify(&mpc).unwrap();
+    for mpc in mpcs.iter_mut() {
+        let mut rng = derive_rng_from_seed(&[0u8; 32]);
+        let before = mpc.clone();
+        // it is _not_ safe to use it yet, there must be 1 contribution
+        mpc.contribute(BatchExpMode::Auto, &mut rng).unwrap();
 
-    mpc
+        before.verify(&mpc).unwrap();
+    }
+
+    let full_mpc_after = MPCParameters::<E>::combine(&queries, &mpcs).unwrap();
+    let mut full_mpc_after_serialized = vec![];
+    full_mpc_after
+        .write(&mut full_mpc_after_serialized, UseCompression::Yes)
+        .unwrap();
+    verify::<E>(
+        &mut full_mpc_before_serialized,
+        &mut full_mpc_after_serialized,
+        3,
+        UseCompression::Yes,
+        CheckForCorrectness::Full,
+    )
+    .unwrap();
+
+    full_mpc_after
 }
 
 #[test]
@@ -87,23 +182,28 @@ fn test_groth_bw6() {
 }
 
 fn groth_test_curve<E: PairingEngine>() {
-    let rng = &mut thread_rng();
-    // generate the params
-    let params: Parameters<E> = {
-        let c = TestCircuit::<E>(None);
-        let setup = generate_mpc_parameters(c, rng);
-        setup.get_params().clone()
-    };
-
-    // Prepare the verification key (for proof verification)
-    let pvk = prepare_verifying_key(&params.vk);
-
-    // Create a proof with these params
-    let proof = {
-        let c = TestCircuit::<E>(Some(<E::Fr as PrimeField>::BigInt::from(5).into()));
-        create_random_proof(c, &params, rng).unwrap()
-    };
-
-    let res = verify_proof(&pvk, &proof, &[<E::Fr as PrimeField>::BigInt::from(25).into()]);
-    assert!(res.is_ok());
+    for contribution_mode in &[Phase2ContributionMode::Full, Phase2ContributionMode::Chunked] {
+        let rng = &mut thread_rng();
+        // generate the params
+        let params: Parameters<E> = {
+            let c = TestCircuit::<E>(None);
+            let setup = match contribution_mode {
+                Phase2ContributionMode::Full => generate_mpc_parameters(c, rng),
+                Phase2ContributionMode::Chunked => generate_mpc_parameters_chunked(c),
+            };
+            setup.get_params().clone()
+        };
+
+        // Prepare the verification key (for proof verification)
+        let pvk = prepare_verifying_key(&params.vk);
+
+        // Create a proof with these params
+        let proof = {
+            let c = TestCircuit::<E>(Some(<E::Fr as PrimeField>::BigInt::from(5).into()));
+            create_random_proof(c, &params, rng).unwrap()
+        };
+
+        let res = verify_proof(&pvk, &proof, &[<E::Fr as PrimeField>::BigInt::from(25).into()]);
+        assert!(res.unwrap());
+    }
 }
diff --git a/setup-utils/Cargo.toml b/setup-utils/Cargo.toml
index f4fd744..c9213ea 100644
--- a/setup-utils/Cargo.toml
+++ b/setup-utils/Cargo.toml
@@ -14,9 +14,10 @@ name = "math"
 harness = false
 
 [dependencies]
-zexe_algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra" }
-zexe_fft = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "ff-fft", default-features = false }
-zexe_r1cs_core = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "r1cs-core" }
+algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra" }
+fft = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "ff-fft", default-features = false }
+r1cs_core = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "r1cs-core" }
+groth16 = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "groth16", features = [] }
 
 blake2 = { version = "0.8.1" }
 blake2s_simd = { version = "0.5.10" }
@@ -34,7 +35,7 @@ typenum = { version = "1.11.2" }
 [dev-dependencies]
 phase1 = { path = "../phase1" }
 
-zexe_algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra", features = ["bls12_377", "bw6_761"] }
+algebra = { git = "https://github.com/scipr-lab/zexe", version = "0.1.1-alpha.0", package = "algebra", features = ["bls12_377", "bw6_761"] }
 
 criterion = { version = "0.3.1" }
 rusty-hook = { version = "0.11.2" }
@@ -44,4 +45,4 @@ default = ["parallel"]
 cli = ["parallel", "rust-crypto"]
 wasm = ["rand/wasm-bindgen"]
 
-parallel = ["rayon", "zexe_algebra/parallel", "zexe_fft/parallel"]
+parallel = ["rayon", "algebra/parallel", "fft/parallel"]
diff --git a/setup-utils/benches/io.rs b/setup-utils/benches/io.rs
index dfe205a..2c3dffc 100644
--- a/setup-utils/benches/io.rs
+++ b/setup-utils/benches/io.rs
@@ -1,6 +1,6 @@
 use setup_utils::{BatchDeserializer, BatchSerializer, UseCompression};
 
-use zexe_algebra::{AffineCurve, Bls12_377, PairingEngine};
+use algebra::{AffineCurve, Bls12_377, PairingEngine};
 
 use criterion::{criterion_group, criterion_main, Criterion, Throughput};
 
diff --git a/setup-utils/benches/math.rs b/setup-utils/benches/math.rs
index 39ded46..11a8226 100644
--- a/setup-utils/benches/math.rs
+++ b/setup-utils/benches/math.rs
@@ -1,7 +1,7 @@
 use phase1::helpers::testing::random_point_vec;
 use setup_utils::{batch_exp, dense_multiexp, generate_powers_of_tau, BatchExpMode};
 
-use zexe_algebra::{
+use algebra::{
     bls12_377::{Bls12_377, G1Affine},
     AffineCurve, Field, PairingEngine, PrimeField, UniformRand, Zero,
 };
diff --git a/phase1/src/helpers/converters.rs b/setup-utils/src/converters.rs
similarity index 89%
rename from phase1/src/helpers/converters.rs
rename to setup-utils/src/converters.rs
index b844231..003efee 100644
--- a/phase1/src/helpers/converters.rs
+++ b/setup-utils/src/converters.rs
@@ -1,5 +1,16 @@
-use crate::{ContributionMode, ProvingSystem};
-use setup_utils::{BatchExpMode, SubgroupCheckMode};
+use crate::{BatchExpMode, SubgroupCheckMode};
+
+#[derive(Clone, PartialEq, Eq, Debug, Copy)]
+pub enum ContributionMode {
+    Full,
+    Chunked,
+}
+
+#[derive(Clone, Copy, PartialEq, Eq, Debug)]
+pub enum ProvingSystem {
+    Groth16,
+    Marlin,
+}
 
 #[derive(Debug, Clone)]
 pub enum CurveKind {
diff --git a/setup-utils/src/elements.rs b/setup-utils/src/elements.rs
index c6b5d1f..c04764f 100644
--- a/setup-utils/src/elements.rs
+++ b/setup-utils/src/elements.rs
@@ -1,3 +1,12 @@
+use crate::{BatchDeserializer, Error};
+use algebra::{
+    batch_verify_in_subgroup, cfg_iter, AffineCurve, CanonicalDeserialize, CanonicalSerialize, FpParameters,
+    PrimeField, Read, SerializationError, Write, Zero,
+};
+
+#[cfg(not(feature = "wasm"))]
+use rayon::prelude::*;
+
 use std::fmt;
 
 /// Determines if point compression should be used.
@@ -92,3 +101,70 @@ impl fmt::Display for SubgroupCheckMode {
         }
     }
 }
+
+pub fn deserialize<T: CanonicalDeserialize, R: Read>(
+    reader: R,
+    compressed: UseCompression,
+    check_correctness: CheckForCorrectness,
+) -> core::result::Result<T, SerializationError> {
+    match (compressed, check_correctness) {
+        (UseCompression::No, CheckForCorrectness::No) => {
+            CanonicalDeserialize::deserialize_uncompressed_unchecked(reader)
+        }
+        (UseCompression::Yes, CheckForCorrectness::No) => CanonicalDeserialize::deserialize_unchecked(reader),
+        (UseCompression::No, CheckForCorrectness::Full) => CanonicalDeserialize::deserialize_uncompressed(reader),
+        (UseCompression::Yes, CheckForCorrectness::Full) => CanonicalDeserialize::deserialize(reader),
+        (..) => Err(SerializationError::InvalidData),
+    }
+}
+
+pub fn serialize<T: CanonicalSerialize, W: Write>(
+    element: &T,
+    writer: W,
+    compressed: UseCompression,
+) -> core::result::Result<(), SerializationError> {
+    match compressed {
+        UseCompression::No => CanonicalSerialize::serialize_uncompressed(element, writer),
+        UseCompression::Yes => CanonicalSerialize::serialize(element, writer),
+    }
+}
+
+pub fn check_subgroup<C: AffineCurve>(
+    elements: &[C],
+    subgroup_check_mode: SubgroupCheckMode,
+) -> core::result::Result<(), Error> {
+    const SECURITY_PARAM: usize = 128;
+    const BATCH_SIZE: usize = 1 << 12;
+    let all_in_prime_order_subgroup = match (elements.len() > BATCH_SIZE, subgroup_check_mode) {
+        (true, SubgroupCheckMode::Auto) | (_, SubgroupCheckMode::Batched) => {
+            match batch_verify_in_subgroup(elements, SECURITY_PARAM, &mut rand::thread_rng()) {
+                Ok(()) => true,
+                _ => false,
+            }
+        }
+        (false, SubgroupCheckMode::Auto) | (_, SubgroupCheckMode::Direct) => cfg_iter!(elements).all(|p| {
+            p.mul(<<C::ScalarField as PrimeField>::Params as FpParameters>::MODULUS)
+                .is_zero()
+        }),
+    };
+    if !all_in_prime_order_subgroup {
+        return Err(Error::IncorrectSubgroup);
+    }
+
+    Ok(())
+}
+
+pub fn read_vec<G: AffineCurve, R: Read>(
+    mut reader: R,
+    compressed: UseCompression,
+    check_for_correctness: CheckForCorrectness,
+) -> Result<Vec<G>, Error> {
+    let size = match compressed {
+        UseCompression::Yes => G::SERIALIZED_SIZE,
+        UseCompression::No => G::UNCOMPRESSED_SIZE,
+    };
+    let length = u64::deserialize(&mut reader)? as usize;
+    let mut bytes = vec![0u8; length * size];
+    reader.read_exact(&mut bytes)?;
+    bytes.read_batch(compressed, check_for_correctness)
+}
diff --git a/setup-utils/src/errors.rs b/setup-utils/src/errors.rs
index 9eba5fb..3c78574 100644
--- a/setup-utils/src/errors.rs
+++ b/setup-utils/src/errors.rs
@@ -1,7 +1,7 @@
 use crate::ElementType;
 
-use zexe_algebra::SerializationError;
-use zexe_r1cs_core::SynthesisError;
+use algebra::SerializationError;
+use r1cs_core::SynthesisError;
 
 use std::io;
 use thiserror::Error;
diff --git a/setup-utils/src/groth16_utils.rs b/setup-utils/src/groth16_utils.rs
index a8627dc..6a44105 100644
--- a/setup-utils/src/groth16_utils.rs
+++ b/setup-utils/src/groth16_utils.rs
@@ -2,8 +2,8 @@
 /// to Phase 2-compatible Lagrange Coefficients.
 use crate::{buffer_size, CheckForCorrectness, Deserializer, Result, Serializer, UseCompression};
 
-use zexe_algebra::{AffineCurve, PairingEngine, PrimeField, ProjectiveCurve};
-use zexe_fft::{
+use algebra::{AffineCurve, PairingEngine, PrimeField, ProjectiveCurve};
+use fft::{
     cfg_into_iter, cfg_iter,
     domain::{radix2::Radix2EvaluationDomain, EvaluationDomain},
 };
@@ -271,7 +271,7 @@ mod tests {
         Phase1, Phase1Parameters, ProvingSystem,
     };
 
-    use zexe_algebra::Bls12_377;
+    use algebra::Bls12_377;
 
     fn read_write_curve<E: PairingEngine>(powers: usize, prepared_phase1_size: usize, compressed: UseCompression) {
         fn compat(compression: UseCompression) -> UseCompressionPhase1 {
diff --git a/setup-utils/src/helpers.rs b/setup-utils/src/helpers.rs
index 4185ff7..8e5127c 100644
--- a/setup-utils/src/helpers.rs
+++ b/setup-utils/src/helpers.rs
@@ -3,11 +3,11 @@ use crate::{
     errors::{Error, VerificationError},
     Result,
 };
-use zexe_algebra::{
+use algebra::{
     AffineCurve, BatchGroupArithmeticSlice, BigInteger, CanonicalSerialize, ConstantSerializedSize, Field, One,
     PairingEngine, PrimeField, ProjectiveCurve, UniformRand, Zero,
 };
-use zexe_fft::{cfg_chunks_mut, cfg_into_iter, cfg_iter, cfg_iter_mut};
+use fft::{cfg_chunks_mut, cfg_into_iter, cfg_iter, cfg_iter_mut};
 
 use blake2::{digest::generic_array::GenericArray, Blake2b, Digest};
 use rand::{rngs::OsRng, thread_rng, Rng, SeedableRng};
@@ -54,7 +54,13 @@ pub fn print_hash(hash: &[u8]) {
 }
 
 /// Multiply a large number of points by a scalar
-pub fn batch_mul<C: AffineCurve>(bases: &mut [C], coeff: &C::ScalarField) -> Result<()> {
+pub fn batch_mul<C: AffineCurve>(bases: &mut [C], coeff: &C::ScalarField, batch_exp_mode: BatchExpMode) -> Result<()> {
+    let exps = vec![*coeff; bases.len()];
+    batch_exp(bases, &exps, None, batch_exp_mode)
+}
+
+/// Multiply a large number of points by a scalar
+pub fn batch_mul_old<C: AffineCurve>(bases: &mut [C], coeff: &C::ScalarField) -> Result<()> {
     let coeff = coeff.into_repr();
     let mut points: Vec<_> = cfg_iter!(bases).map(|base| base.mul(coeff)).collect();
     C::Projective::batch_normalization(&mut points);
@@ -285,7 +291,7 @@ pub fn from_slice(bytes: &[u8]) -> [u8; 32] {
 #[cfg(test)]
 mod tests {
     use super::*;
-    use zexe_algebra::{
+    use algebra::{
         bls12_377::Bls12_377,
         bls12_381::{Bls12_381, Fr, G1Affine, G2Affine},
     };
diff --git a/setup-utils/src/io/mod.rs b/setup-utils/src/io/mod.rs
index 3a22dca..733ae8f 100644
--- a/setup-utils/src/io/mod.rs
+++ b/setup-utils/src/io/mod.rs
@@ -6,7 +6,7 @@ mod write;
 pub use write::{BatchSerializer, Serializer};
 
 use crate::UseCompression;
-use zexe_algebra::AffineCurve;
+use algebra::AffineCurve;
 
 pub fn buffer_size<C: AffineCurve>(compression: UseCompression) -> usize {
     if compression == UseCompression::Yes {
@@ -21,7 +21,7 @@ mod tests {
     use super::*;
     use phase1::helpers::testing::random_point_vec;
 
-    use zexe_algebra::bls12_377::{G1Affine, G2Affine};
+    use algebra::bls12_377::{G1Affine, G2Affine};
 
     use crate::CheckForCorrectness;
     use rand::thread_rng;
diff --git a/setup-utils/src/io/read.rs b/setup-utils/src/io/read.rs
index 6e8dc4b..58d2bdf 100644
--- a/setup-utils/src/io/read.rs
+++ b/setup-utils/src/io/read.rs
@@ -1,7 +1,7 @@
 use crate::{buffer_size, CheckForCorrectness, Error, Result, UseCompression};
 
-use zexe_algebra::AffineCurve;
-use zexe_fft::cfg_chunks;
+use algebra::AffineCurve;
+use fft::cfg_chunks;
 
 #[cfg(feature = "parallel")]
 use rayon::prelude::*;
diff --git a/setup-utils/src/io/write.rs b/setup-utils/src/io/write.rs
index 5bed237..21172d1 100644
--- a/setup-utils/src/io/write.rs
+++ b/setup-utils/src/io/write.rs
@@ -1,8 +1,8 @@
 //! Utilities for writing and reading group elements to buffers in parallel
 use crate::{buffer_size, Result, UseCompression};
 
-use zexe_algebra::AffineCurve;
-use zexe_fft::cfg_chunks_mut;
+use algebra::AffineCurve;
+use fft::cfg_chunks_mut;
 
 #[cfg(feature = "parallel")]
 use rayon::prelude::*;
diff --git a/setup-utils/src/lib.rs b/setup-utils/src/lib.rs
index 2289b8e..a4ffeb7 100644
--- a/setup-utils/src/lib.rs
+++ b/setup-utils/src/lib.rs
@@ -12,7 +12,10 @@ mod groth16_utils;
 pub use groth16_utils::Groth16Params;
 
 mod elements;
-pub use elements::{BatchExpMode, CheckForCorrectness, ElementType, SubgroupCheckMode, UseCompression};
+pub use elements::{
+    check_subgroup, deserialize, read_vec, serialize, BatchExpMode, CheckForCorrectness, ElementType,
+    SubgroupCheckMode, UseCompression,
+};
 
 mod helpers;
 pub use helpers::*;
@@ -29,4 +32,5 @@ pub use seed::derive_rng_from_seed;
 pub use blake2::digest::generic_array::GenericArray;
 pub use typenum::U64;
 
-pub use zexe_fft::{cfg_chunks, cfg_into_iter, cfg_iter_mut};
+pub use fft::{cfg_chunks, cfg_into_iter, cfg_iter_mut};
+pub mod converters;
